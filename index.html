<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/maolu.github.io/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/maolu.github.io/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/maolu.github.io/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/maolu.github.io/images/logo.svg" color="#222">

<link rel="stylesheet" href="/maolu.github.io/css/main.css">


<link rel="stylesheet" href="/maolu.github.io/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"maolululu.github.io","root":"/maolu.github.io/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Happy Coding">
<meta property="og:type" content="website">
<meta property="og:title" content="maolu">
<meta property="og:url" content="https://maolululu.github.io/maolu.github.io/index.html">
<meta property="og:site_name" content="maolu">
<meta property="og:description" content="Happy Coding">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="maolu">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://maolululu.github.io/maolu.github.io/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>maolu</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/maolu.github.io/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">maolu</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/maolu.github.io/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/maolu.github.io/about/me.html" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/maolu.github.io/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/maolu.github.io/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/maolu.github.io/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://maolululu.github.io/maolu.github.io/2021/05/09/jd/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/maolu.github.io/images/toux.gif">
      <meta itemprop="name" content="maolu">
      <meta itemprop="description" content="Happy Coding">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="maolu">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/maolu.github.io/2021/05/09/jd/" class="post-title-link" itemprop="url">jd</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-05-09 20:23:53 / 修改时间：20:27:00" itemprop="dateCreated datePublished" datetime="2021-05-09T20:23:53+08:00">2021-05-09</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <hr>
<p>title: jd<br>date: 2021-05-09 20:15:13</p>
<hr>
<h1 id="京东全网爬虫"><a href="#京东全网爬虫" class="headerlink" title="京东全网爬虫"></a>京东全网爬虫</h1><h3 id="一-需求"><a href="#一-需求" class="headerlink" title="一  需求"></a>一  需求</h3><h4 id="1-1抓取首页的分类信息"><a href="#1-1抓取首页的分类信息" class="headerlink" title="1.1抓取首页的分类信息"></a>1.1抓取首页的分类信息</h4><p>。大分类名称和URL<br>。中分类名称和URL<br>。小分类名称和URL</p>
<h4 id="1-2抓取商品信息"><a href="#1-2抓取商品信息" class="headerlink" title="1.2抓取商品信息"></a>1.2抓取商品信息</h4><p>。商品名称<br>。商品价格<br>。商品评论数量<br>。商品店铺<br>。商品促销<br>。商品选项<br>。商品图片的URL</p>
<h3 id="二-开发环境和技术选择"><a href="#二-开发环境和技术选择" class="headerlink" title="二  开发环境和技术选择"></a>二  开发环境和技术选择</h3><p>●开发语言: Python3<br>●爬虫技术: scrapy. _redis分布式爬虫<br>●存储: MongoDB数据库</p>
<h3 id="三-实现步骤"><a href="#三-实现步骤" class="headerlink" title="三 实现步骤"></a>三 实现步骤</h3><p>1.创建爬虫项目<br>2.根据需求，定义数据数据模型<br>3.实现分类爬虫<br>4.保存分类信息<br>5.实现商品爬虫<br>6.保存商品信息<br>7.实现随机User-Agent和代理IP下载器中间件，解决IP反爬.</p>
<h3 id="四-定义数据模型"><a href="#四-定义数据模型" class="headerlink" title="四 定义数据模型"></a>四 定义数据模型</h3><p>爬虫数据模型只能根据需求，</p>
<p>定义一个大概,随着对项目实现可能会对数据模型做相应的修改.</p>
<h4 id="类别数据模型"><a href="#类别数据模型" class="headerlink" title="类别数据模型"></a>类别数据模型</h4> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">●类别数据模型类:用于存储类别信息(Category) -字段:</span></span><br><span class="line"><span class="string">。b_category_name:大类别名称</span></span><br><span class="line"><span class="string">。b_category_url:大类别URL</span></span><br><span class="line"><span class="string">。m_category_name:中分类名称</span></span><br><span class="line"><span class="string">。m_category_url: 中分类URL</span></span><br><span class="line"><span class="string">。s_category_name:小分类名称</span></span><br><span class="line"><span class="string">。s_category_url: 小分类URL</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Category</span>(<span class="params">scrapy.item</span>):</span></span><br><span class="line"></span><br><span class="line">    b_category_name = scrapy.Field()</span><br><span class="line">    b_category_url = scrapy.Field()</span><br><span class="line">    m_category_name = scrapy.Field()</span><br><span class="line">    m_category_url = scrapy.Field()</span><br><span class="line">    s_category_name = scrapy.Field()</span><br><span class="line">    s_category_url = scrapy.Field()</span><br></pre></td></tr></table></figure>



<h4 id="类别数据模型-1"><a href="#类别数据模型-1" class="headerlink" title="类别数据模型"></a>类别数据模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">商品数据模型</span></span><br><span class="line"><span class="string">●商品数据模型类:用于存储商品信息(Product)</span></span><br><span class="line"><span class="string">●字段:</span></span><br><span class="line"><span class="string">。product_category: 商品类别</span></span><br><span class="line"><span class="string">。product_sku_id: 商品ID</span></span><br><span class="line"><span class="string">。product_napne: 商品名称</span></span><br><span class="line"><span class="string">。product_img_url: 商品图片URL</span></span><br><span class="line"><span class="string">。product_book_info: 图书信息,作者,出版社</span></span><br><span class="line"><span class="string">。product_option: 商品选项</span></span><br><span class="line"><span class="string">。product_shop:商品店铺</span></span><br><span class="line"><span class="string">。product_comments:商品评论数量</span></span><br><span class="line"><span class="string">。product_ad: 商品促销</span></span><br><span class="line"><span class="string">。product_price: 商品价格</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Product</span>(<span class="params">scrapy.item</span>):</span></span><br><span class="line"></span><br><span class="line">    product_category = scrapy.Field()</span><br><span class="line">    product_sku_id = scrapy.Field()</span><br><span class="line">    product_napne = scrapy.Field()</span><br><span class="line">    product_img_url = scrapy.Field()</span><br><span class="line">    product_book_info = scrapy.Field()</span><br><span class="line">    product_option = scrapy.Field()</span><br><span class="line">    product_shop = scrapy.Field()</span><br><span class="line">    product_comments = scrapy.Field()</span><br><span class="line">    product_ad = scrapy.Field()</span><br><span class="line">    product_price = scrapy.Field()</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="五-商品分类爬虫"><a href="#五-商品分类爬虫" class="headerlink" title="五 商品分类爬虫"></a>五 商品分类爬虫</h3><p>目标 : 抓取各级分类信息</p>
<p>步骤：</p>
<ol>
<li><p>分析页面，确定分类信息的url</p>
<p>​    <a target="_blank" rel="noopener" href="https://dc.3.cn/category/get">https://dc.3.cn/category/get</a></p>
</li>
<li><p>创建类别爬虫，抓取数据</p>
<ol>
<li><p>使用框架  scrapy genspider id_categorg jb.com</p>
</li>
<li><p>指定起始url  <a target="_blank" rel="noopener" href="https://dc.3.cn/category/get">https://dc.3.cn/category/get</a></p>
</li>
<li><p>测试运行  scrapy crawl jb_category</p>
</li>
<li><p>解析 数据交给引擎</p>
<p>1.分析数据格式（主要有三种）</p>
<pre><code>    * list.jd.com/list.html?cat=6233,6235|遥控/电动||0
    *  1713-3258-6569|科幻||0                 将 &#39;-&#39; 替换为 &#39;,&#39;        url为        https://list.jd.com/list.html?cat=&#123; &#125;
    * 1713-3272|动漫||0                       url 为     https://channel.jd.com/&#123;&#125;.html
</code></pre>
</li>
</ol>
</li>
</ol>
<h3 id="六-保存分类信息"><a href="#六-保存分类信息" class="headerlink" title="六 保存分类信息"></a>六 保存分类信息</h3><p>1.实现保存分类的Pipeline类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">步骤:  </span></span><br><span class="line"><span class="string">1. open_spider方法中,链接MongoDB数据库,获取要操作的集合</span></span><br><span class="line"><span class="string">2. process_item 方法中,向MongoDB中插入类别数据</span></span><br><span class="line"><span class="string">3. close_spider 方法中, 关闭MongoDB的链接</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">from</span> mall_spider.spiders.jd_category <span class="keyword">import</span> JdCategorySpider</span><br><span class="line"><span class="keyword">from</span> mall_spider.settings <span class="keyword">import</span> MONGODB_URL</span><br><span class="line"><span class="keyword">from</span> pymongo <span class="keyword">import</span> MongoClient</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CategoryPipeline</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span>(<span class="params">self,spider</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(spider,JdCategorySpider):</span><br><span class="line">            self.client = MongoClient(MONGODB_URL)</span><br><span class="line">            self.collection = self.client[<span class="string">&#x27;jd&#x27;</span>][<span class="string">&#x27;category&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(spider,JdCategorySpider):</span><br><span class="line">            self.collection.insert_one(<span class="built_in">dict</span>(item))</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span>(<span class="params">self,spider</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(spider,JdCategorySpider):</span><br><span class="line">            self.client.close()</span><br></pre></td></tr></table></figure>



<p>2.在 settings.py开启,类别的Pipeline</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="string">&#x27;mall_spider.pipelines.CategoryPipeline&#x27;</span>: <span class="number">300</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="E:\桌面\jdc.png">      </p>
<h3 id="七-实现商品爬虫"><a href="#七-实现商品爬虫" class="headerlink" title="七 实现商品爬虫"></a>七 实现商品爬虫</h3><h4 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h4><ul>
<li><p>分析,确定数据所在的URL</p>
</li>
<li><p>代码实现(核心)</p>
</li>
<li><p>商品爬虫实现分布式  </p>
</li>
</ul>
<h4 id="分析-确定数据所在的URL"><a href="#分析-确定数据所在的URL" class="headerlink" title="分析,确定数据所在的URL"></a>分析,确定数据所在的URL</h4><ul>
<li>解析列表页,提取商品</li>
<li>sku_ id , 实现翻页,确定翻页的URL</li>
<li>获取商品的基本信息,通过手机抓包(APP),确定URL</li>
<li>PC详情页面,确定商品的促销信息的URL</li>
<li>PC详情页面,确定评论信息的URL</li>
<li>PC详情页面,确定商品价格信息的URL</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> mall_spider.items <span class="keyword">import</span> Product</span><br><span class="line"><span class="keyword">from</span> jsonpath <span class="keyword">import</span> jsonpath</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">步骤:</span></span><br><span class="line"><span class="string">1.重写start_requests方法,根据分类信息构建列表页的请求</span></span><br><span class="line"><span class="string">2.解析列表页,提取商品的skuid,构建商品基本的信息请求;实现翻页</span></span><br><span class="line"><span class="string">    1.确定商品基本的信息请求</span></span><br><span class="line"><span class="string">        1. URL: https://cdnware.m.jd.com/c1/skuDetail/apple/7.3.0/32962088964.json</span></span><br><span class="line"><span class="string">        2.请求方法:GET</span></span><br><span class="line"><span class="string">        3.参数/数据:  32962088964(商品的skuid)</span></span><br><span class="line"><span class="string">    2.解析列表页,提取商品的skuid</span></span><br><span class="line"><span class="string">    3.构建商品基本的信息请求</span></span><br><span class="line"><span class="string">    4.实现列表翻页</span></span><br><span class="line"><span class="string">3.解析商品基本信息,构建商品促销信息的请求</span></span><br><span class="line"><span class="string">    2.构建商品促销信息的请求</span></span><br><span class="line"><span class="string">        1.准备促销信息的请求</span></span><br><span class="line"><span class="string">            1. URL:https://cd.jd.com/promotion/v2?skuld=100000020845&amp;area=1_72_4137_0&amp;cat=737%2C794%2C798</span></span><br><span class="line"><span class="string">            2.方法: GET</span></span><br><span class="line"><span class="string">            3.参数/数据:</span></span><br><span class="line"><span class="string">                1. skuld=100000020845     商品SKU_ID</span></span><br><span class="line"><span class="string">                2. &amp;area=1_ _72_ 4137_ 0  区域,固定值</span></span><br><span class="line"><span class="string">                3. cat=737%2C7949%2C798   :类别</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">4.解析促销信息,构建商品评价信息的请求</span></span><br><span class="line"><span class="string">    1.解析促销信息</span></span><br><span class="line"><span class="string">        1. product. ad :商品促销</span></span><br><span class="line"><span class="string">        2.构建商品评价信息的请求</span></span><br><span class="line"><span class="string">            1.准备评价信息的请求</span></span><br><span class="line"><span class="string">                1. URL:https://club.jd.com/comment/productCommentSummaries.action?referencelds=100000020845</span></span><br><span class="line"><span class="string">                2.方法: GET</span></span><br><span class="line"><span class="string">                3.参数: referencelds=100000020845 :商品的SKU_ _ID</span></span><br><span class="line"><span class="string">5.解析商品评价信息,构建价格信息的请求</span></span><br><span class="line"><span class="string">    1.解析商品评价信息</span></span><br><span class="line"><span class="string">        1. product_ comments :商品评论数量</span></span><br><span class="line"><span class="string">        2.评价数量,好评数量,差评数量,好评率</span></span><br><span class="line"><span class="string">    2.构建价格信息的请求</span></span><br><span class="line"><span class="string">        1.准备价格请求:</span></span><br><span class="line"><span class="string">            1. URL: https://p.3.cn/prices/mgets?skulds=J_6933429</span></span><br><span class="line"><span class="string">            2.请求方法: GET</span></span><br><span class="line"><span class="string">            3.参数: skulds=J. _6933429,j.后跟商品的sku_ _id</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">6.解析价格信息</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JdProductSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;jd_product&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;jd.com&#x27;</span>,<span class="string">&#x27;3.cn&#x27;</span>]</span><br><span class="line">    <span class="comment"># start_urls = [&#x27;http://jd.com/&#x27;]</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span>(<span class="params">self</span>):</span></span><br><span class="line">        category = &#123;</span><br><span class="line">             <span class="string">&quot;b_category_name&quot;</span> : <span class="string">&quot;家用电器&quot;</span>,</span><br><span class="line">             <span class="string">&quot;b_category_url&quot;</span> : <span class="string">&quot;https://jiadian.jd.com&quot;</span>,</span><br><span class="line">             <span class="string">&quot;m_category_name&quot;</span> : <span class="string">&quot;电视&quot;</span>,</span><br><span class="line">             <span class="string">&quot;m_category_url&quot;</span> : <span class="string">&quot;https://list.jd.com/list.html?cat=737,794,798&quot;</span>,</span><br><span class="line">              <span class="string">&quot;s_category_name&quot;</span> : <span class="string">&quot;超薄电视&quot;</span>,</span><br><span class="line">              <span class="string">&quot;s_category_url&quot;</span> : <span class="string">&quot;https://list.jd.com/list.html?cat=737,794,798&amp;ev=4155_76344&amp;sort=sort_rank_asc&amp;trans=1&amp;JL=2_1_0#J_crumbsBar&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment"># 构建列表页的请求</span></span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(category[<span class="string">&#x27;s_category_url&#x27;</span>],callback=self.parse,meta=&#123;<span class="string">&#x27;category&#x27;</span>:category&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        category = response.meta[<span class="string">&#x27;category&#x27;</span>]</span><br><span class="line">        <span class="comment"># print(category)</span></span><br><span class="line">        <span class="comment"># 获取sku_id列表</span></span><br><span class="line">        sku_ids = response.xpath(<span class="string">&#x27;//*[@id=&quot;J_goodsList&quot;]/ul/li/@data-sku&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># print(sku_ids)</span></span><br><span class="line">        <span class="keyword">for</span> sku_id <span class="keyword">in</span> sku_ids:</span><br><span class="line">            item = Product()</span><br><span class="line">            item[<span class="string">&#x27;product_category&#x27;</span>] =category</span><br><span class="line">            item[<span class="string">&#x27;product_sku_id&#x27;</span>] = sku_id</span><br><span class="line">            <span class="comment"># print(item)</span></span><br><span class="line">            <span class="comment"># 构建商品基本信息请求</span></span><br><span class="line">            product_base_url = <span class="string">&#x27;https://cdnware.m.jd.com/c1/skuDetail/apple/9.5.1/&#123;&#125;.json&#x27;</span>.<span class="built_in">format</span>(sku_id)</span><br><span class="line">            <span class="comment"># product_base_url = &#x27;https://item.jd.com/&#123;&#125;.html&#x27;.format(sku_id)</span></span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(product_base_url,callback=self.parse_product_base,meta=&#123;<span class="string">&#x27;item&#x27;</span>:item&#125;)</span><br><span class="line"></span><br><span class="line">        next_url = response.xpath(<span class="string">&#x27;//a[@class=&quot;pn-next&quot;]/@href&#x27;</span>).extract_first()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> next_url:</span><br><span class="line">            next_url = response.urljoin(next_url)</span><br><span class="line">            <span class="comment"># print(next_url)</span></span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(next_url,callback=self.parse,meta=&#123;<span class="string">&#x27;category&#x27;</span>:category&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_product_base</span>(<span class="params">self,response</span>):</span></span><br><span class="line">        item = response.meta[<span class="string">&#x27;item&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        result = json.loads(response.text)</span><br><span class="line">        item[<span class="string">&#x27;product_name&#x27;</span>] = result[<span class="string">&#x27;wareInfo&#x27;</span>][<span class="string">&#x27;basicInfo&#x27;</span>][<span class="string">&#x27;name&#x27;</span>]</span><br><span class="line">        item[<span class="string">&#x27;product_img_url&#x27;</span>] = result[<span class="string">&#x27;wareInfo&#x27;</span>][<span class="string">&#x27;basicInfo&#x27;</span>][<span class="string">&#x27;wareImage&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;small&#x27;</span>]</span><br><span class="line">        item[<span class="string">&#x27;product_book_info&#x27;</span>] = result[<span class="string">&#x27;wareInfo&#x27;</span>][<span class="string">&#x27;basicInfo&#x27;</span>][<span class="string">&#x27;book_info&#x27;</span>]</span><br><span class="line">        color_size = jsonpath(result,<span class="string">&#x27;$..colorSize&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> color_size:</span><br><span class="line">            color_size = color_size[<span class="number">0</span>]</span><br><span class="line">            product_option = &#123;&#125;</span><br><span class="line">            <span class="keyword">for</span> option <span class="keyword">in</span> color_size:</span><br><span class="line">                title = option[<span class="string">&#x27;title&#x27;</span>]</span><br><span class="line">                value = jsonpath(option,<span class="string">&#x27;$..text&#x27;</span>)</span><br><span class="line">                product_option[<span class="string">&#x27;title&#x27;</span>] = value</span><br><span class="line">            item[<span class="string">&#x27;product_option&#x27;</span>] = product_option</span><br><span class="line"></span><br><span class="line">        shop = jsonpath(result,<span class="string">&#x27;$..shop&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> shop:</span><br><span class="line">            shop = shop[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">if</span> shop:</span><br><span class="line">                item[<span class="string">&#x27;product_shop&#x27;</span>] = &#123;</span><br><span class="line">                    <span class="string">&#x27;shop_id&#x27;</span>: shop[<span class="string">&#x27;shopId&#x27;</span>],</span><br><span class="line">                    <span class="string">&#x27;shop_name&#x27;</span>: shop[<span class="string">&#x27;name&#x27;</span>],</span><br><span class="line">                    <span class="string">&#x27;shop_score&#x27;</span>:shop[<span class="string">&#x27;score&#x27;</span>]</span><br><span class="line">                &#125;</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                item[<span class="string">&#x27;product__shop&#x27;</span>] =&#123;</span><br><span class="line">                    <span class="string">&#x27;shop_name&#x27;</span>:<span class="string">&#x27;京东自营&#x27;</span></span><br><span class="line">                &#125;</span><br><span class="line">        item[<span class="string">&#x27;product_caregory&#x27;</span>] = result[<span class="string">&#x27;wareInfo&#x27;</span>][<span class="string">&#x27;basicInfo&#x27;</span>][<span class="string">&#x27;name&#x27;</span>]</span><br><span class="line">        item[<span class="string">&#x27;product_caregory&#x27;</span>] =  item[<span class="string">&#x27;product_caregory&#x27;</span>].replace(<span class="string">&#x27;;&#x27;</span>,<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 促销信息url</span></span><br><span class="line">        ad_url = <span class="string">&#x27;https://cd.jd.com/promotion/v2?skuld=&#123;&#125;&amp;area=1_72_4137_0&amp;cat=&#123;&#125;&#x27;</span>\</span><br><span class="line">                .<span class="built_in">format</span>(item[<span class="string">&#x27;product_sku_id&#x27;</span>],item[<span class="string">&#x27;product_category_id&#x27;</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(ad_url,callback=self.parse_product_ad,meta=&#123;<span class="string">&#x27;item&#x27;</span>:item&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_product_ad</span>(<span class="params">self,reponse</span>):</span></span><br><span class="line">        item = reponse.meta[<span class="string">&#x27;item&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        result  = json.loads(reponse.body.decode(<span class="string">&#x27;GBK&#x27;</span>))</span><br><span class="line"></span><br><span class="line">        item[<span class="string">&#x27;product_ad&#x27;</span>] = jsonpath(result,<span class="string">&#x27;$..ad&#x27;</span>)[<span class="number">0</span>]  <span class="keyword">if</span> jsonpath(result,<span class="string">&#x27;$..ad&#x27;</span>) <span class="keyword">else</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        comments_url = <span class="string">&#x27;https://club.jd.com/comment/productCommentSummaries.action?referencelds=&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(item[<span class="string">&#x27;product_sku_id&#x27;</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(comments_url,callback=self.parse_product_comments,meta=&#123;<span class="string">&#x27;item&#x27;</span>:item&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_product_comments</span>(<span class="params">self,reponse</span>):</span></span><br><span class="line">        item = reponse.meta[<span class="string">&#x27;item&#x27;</span>]</span><br><span class="line">        result = json.loads(reponse.text)</span><br><span class="line"></span><br><span class="line">        item[<span class="string">&#x27;product_comments&#x27;</span>] = &#123;</span><br><span class="line">            <span class="string">&#x27;CommentCount&#x27;</span>:jsonpath(result,<span class="string">&#x27;$..CommentCount&#x27;</span>)[<span class="number">0</span>],</span><br><span class="line">            <span class="string">&#x27;GoodCount&#x27;</span>: jsonpath(result,<span class="string">&#x27;$..GoodCount&#x27;</span>)[<span class="number">0</span>],</span><br><span class="line">            <span class="string">&#x27;PoolCount&#x27;</span>: jsonpath(result,<span class="string">&#x27;$..PoolCount&#x27;</span>)[<span class="number">0</span>],</span><br><span class="line">            <span class="string">&#x27;GoodRate&#x27;</span>: jsonpath(result,<span class="string">&#x27;$..GoodRate&#x27;</span>)[<span class="number">0</span>],</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        price_url = <span class="string">&#x27;https://p.3.cn/prices/mgets?skulds=J_&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(item[<span class="string">&#x27;product_sku_id&#x27;</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(price_url,callback=self.parse_product_price,meta=&#123;<span class="string">&#x27;item&#x27;</span>:item&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_product_price</span>(<span class="params">self,resonse</span>):</span></span><br><span class="line">        item = resonse.meta[<span class="string">&#x27;item&#x27;</span>]</span><br><span class="line">        result  = json.loads(resonse.text)</span><br><span class="line"></span><br><span class="line">        item[<span class="string">&#x27;product_price&#x27;</span>] =result[<span class="number">0</span>][<span class="string">&#x27;p&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure>



<h4 id="实现分布式"><a href="#实现分布式" class="headerlink" title="实现分布式"></a>实现分布式</h4><p>步骤:<br>1.修改爬虫类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    1.修改继承关系:继承RedisSpider  </span></span><br><span class="line"><span class="string">    2.指定redis_key</span></span><br><span class="line"><span class="string">    3.把重写start_requests 改为重写make_ request from_ data   #注意用 return返回</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JdProductSpider</span>(<span class="params">RedisSpider</span>):</span> </span><br><span class="line">    name = <span class="string">&#x27;jd_product&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;jd.com&#x27;</span>,<span class="string">&#x27;3.cn&#x27;</span>]</span><br><span class="line">    <span class="comment"># start_urls = [&#x27;http://jd.com/&#x27;]</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 指定redis_key : 用于指定起始URL列表，在Redis数据库中的key</span></span><br><span class="line">    redis_key = <span class="string">&#x27;jd_product:category&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 把重写start_requests 改为重写make_request_from_data</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    def start_requests(self):</span></span><br><span class="line"><span class="string">        category = &#123;</span></span><br><span class="line"><span class="string">             &quot;b_category_name&quot; : &quot;家用电器&quot;,</span></span><br><span class="line"><span class="string">             &quot;b_category_url&quot; : &quot;https://jiadian.jd.com&quot;,</span></span><br><span class="line"><span class="string">             &quot;m_category_name&quot; : &quot;电视&quot;,</span></span><br><span class="line"><span class="string">             &quot;m_category_url&quot; : &quot;https://list.jd.com/list.html?cat=737,794,798&quot;,</span></span><br><span class="line"><span class="string">              &quot;s_category_name&quot; : &quot;超薄电视&quot;,</span></span><br><span class="line"><span class="string">              &quot;s_category_url&quot; : &quot;https://list.jd.com/list.html?cat=737,794,798&amp;ev=4155_76344&amp;sort=sort_rank_asc&amp;trans=1&amp;JL=2_1_0#J_crumbsBar&quot;</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">        # 构建列表页的请求</span></span><br><span class="line"><span class="string">        yield scrapy.Request(category[&#x27;s_category_url&#x27;],callback=self.parse,meta=&#123;&#x27;category&#x27;:category&#125;)</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_request_from_data</span>(<span class="params">self, data</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        根据 redis中读取的分类信息的二进制数据，构建请求</span></span><br><span class="line"><span class="string">        :param data: 分类信息的二进制数据</span></span><br><span class="line"><span class="string">        :return: 请求对象</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        category = pickle.loads(data)</span><br><span class="line">        <span class="keyword">return</span> scrapy.Request(category[<span class="string">&#x27;s_category_url&#x27;</span>],callback=self.parse,meta=&#123;<span class="string">&#x27;category&#x27;</span>:category&#125;)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>2.在settings文件中配置scrapy_ redis</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-------------配置scrapy_ redis-------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># REDIS数据链接</span></span><br><span class="line">REDIS_URL = <span class="string">&#x27;redis://127.0.0.1:6379/0&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#去重容器类:用于把已爬指纹存储到基于Redi s的set集合中</span></span><br><span class="line">DUPEFILTER_CLASS = <span class="string">&quot;scrapy_redis.dupefilter.RFPDupeFilter&quot;</span></span><br><span class="line"><span class="comment">#调度器:用于把待爬请求存储到基于Redi s的队列</span></span><br><span class="line">SCHEDULER = <span class="string">&quot;scrapy_redis.scheduler.Scheduler&quot;</span></span><br><span class="line"><span class="comment">#是不进行调度持久化:</span></span><br><span class="line"><span class="comment">#如果是True,当程序结束的时候，会保留Redi s中已爬指纹和待爬的请求</span></span><br><span class="line"><span class="comment">#如果是False, 当程序结束的时候，会清空Redis中已爬指纹和待爬的请求</span></span><br><span class="line">SCHEDULER_PERSIST = <span class="literal">True</span></span><br></pre></td></tr></table></figure>

<p>3.写一个程序用于把MongoDB中分类信息,放入到爬虫redis_ key指定的列表中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">步骤:</span></span><br><span class="line"><span class="string">1. 在项目文件夹下创建add_ category_ to_ redis.py</span></span><br><span class="line"><span class="string">2.实现方法 add_category_to_redis :</span></span><br><span class="line"><span class="string">    1.链接 MongoDB</span></span><br><span class="line"><span class="string">    2.链接 Redis</span></span><br><span class="line"><span class="string">    3.读取 MongoDB中分类信息,序列化后,添加到商品爬虫redis_ key指定的list</span></span><br><span class="line"><span class="string">    4.关闭 MongoDB</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">3.在 if __name__ == &#x27;__main__&#x27;: 中调用add_category_to_redis方法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">from</span>  pymongo <span class="keyword">import</span> MongoClient</span><br><span class="line"><span class="keyword">from</span> redis <span class="keyword">import</span> StrictRedis</span><br><span class="line"><span class="keyword">from</span> mall_spider.settings <span class="keyword">import</span> MONGODB_URL,REDIS_URL</span><br><span class="line"><span class="keyword">from</span> mall_spider.spiders.jd_product <span class="keyword">import</span> JdProductSpider</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_category_to_redis</span>():</span></span><br><span class="line">    mongo = MongoClient(MONGODB_URL)</span><br><span class="line">    redis = StrictRedis.from_url(REDIS_URL)</span><br><span class="line">    collection = mongo[<span class="string">&#x27;jd&#x27;</span>][<span class="string">&#x27;category&#x27;</span>]</span><br><span class="line">    cursor = collection.find()</span><br><span class="line">    <span class="keyword">for</span> category <span class="keyword">in</span> cursor:</span><br><span class="line">        data = pickle.dumps(category)</span><br><span class="line">        redis.lpush(JdProductSpider.redis_key,data)</span><br><span class="line">    mongo.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    add_category_to_redis()</span><br></pre></td></tr></table></figure>





<h3 id="保存爬取信息"><a href="#保存爬取信息" class="headerlink" title="保存爬取信息"></a>保存爬取信息</h3><p>步骤:<br>1.实现存储商品Pipeline类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">步骤</span></span><br><span class="line"><span class="string">。在open_spider方法,建立MongoDB数据库连接,获取要操作的集合</span></span><br><span class="line"><span class="string">。在process_item方法，把数据插入到MongoDB中</span></span><br><span class="line"><span class="string">。在close_spider方法,关闭数据库连接</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">from</span> mall_spider.spiders.jd_product <span class="keyword">import</span> JdProductSpider</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ProductPipeline</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span>(<span class="params">self,spider</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(spider, JdProductSpider):</span><br><span class="line">            self.client = MongoClient(MONGODB_URL)</span><br><span class="line">            self.collection = self.client[<span class="string">&#x27;jd&#x27;</span>][<span class="string">&#x27;product&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(spider, JdProductSpider):</span><br><span class="line">            self.collection.insert_one(<span class="built_in">dict</span>(item))</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(spider, JdProductSpider):</span><br><span class="line">            self.client.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>2.在settings.py中开启这个管道</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="comment"># 分类爬虫管道</span></span><br><span class="line">    <span class="string">&#x27;mall_spider.pipelines.CategoryPipeline&#x27;</span>: <span class="number">300</span>,</span><br><span class="line">    <span class="comment"># 商品爬虫管道</span></span><br><span class="line">    <span class="string">&#x27;mall_spider.pipelines.ProductPipeline&#x27;</span>: <span class="number">301</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<h3 id="八-实现下载器中间件"><a href="#八-实现下载器中间件" class="headerlink" title="八 实现下载器中间件"></a>八 实现下载器中间件</h3><p>为了避免IP反爬,实现随机User-Agent和代理IP的中间件<br>步骤:<br>1.实现随机User- Agent的中间件</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">1.实现随机User-Agent的中间件</span></span><br><span class="line"><span class="string">步骤</span></span><br><span class="line"><span class="string">    准备User-Agent列表</span></span><br><span class="line"><span class="string">    在middlewares.py中, 实现RandomUserAgent类</span></span><br><span class="line"><span class="string">    实现process_request方法</span></span><br><span class="line"><span class="string">如果是请求是https://cdnware.m.jd.com 开头的,就是设置-个iPhone的user-agent</span></span><br><span class="line"><span class="string">否则从User-Agent列表中随机取出一个</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">User_Agent = [ <span class="string">&quot;Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; AcooBrowser; .NET CLR 1.1.4322; .NET CLR 2.0.50727)&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0; Acoo Browser; SLCC1; .NET CLR 2.0.50727; Media Center PC 5.0; .NET CLR 3.0.04506)&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Mozilla/4.0 (compatible; MSIE 7.0; AOL 9.5; AOLBuild 4337.35; Windows NT 5.1; .NET CLR 1.1.4322; .NET CLR 2.0.50727)&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Mozilla/5.0 (Windows; U; MSIE 9.0; Windows NT 9.0; en-US)&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 2.0.50727; Media Center PC 6.0)&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 1.0.3705; .NET CLR 1.1.4322)&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Mozilla/4.0 (compatible; MSIE 7.0b; Windows NT 5.2; .NET CLR 1.1.4322; .NET CLR 2.0.50727; InfoPath.2; .NET CLR 3.0.04506.30)&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN) AppleWebKit/523.15 (KHTML, like Gecko, Safari/419.3) Arora/0.3 (Change: 287 c9dfb30)&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Mozilla/5.0 (X11; U; Linux; en-US) AppleWebKit/527+ (KHTML, like Gecko, Safari/419.3) Arora/0.6&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.2pre) Gecko/20070215 K-Ninja/2.1.1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN; rv:1.9) Gecko/20080705 Firefox/3.0 Kapiko/3.0&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Mozilla/5.0 (X11; Linux i686; U;) Gecko/20070322 Kazehakase/0.4.5&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.8) Gecko Fedora/1.9.0.8-1.fc10 Kazehakase/0.5.6&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_3) AppleWebKit/535.20 (KHTML, like Gecko) Chrome/19.0.1036.7 Safari/535.20&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Opera/9.80 (Macintosh; Intel Mac OS X 10.6.8; U; fr) Presto/2.9.168 Version/11.52&quot;</span>,</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomUserAgent</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span>(<span class="params">self, request, spider</span>):</span></span><br><span class="line">        <span class="keyword">if</span> request.url.startswith(<span class="string">&#x27;https://cdnware.m.jd.com&#x27;</span>):</span><br><span class="line">            request.headers[<span class="string">&#x27;user-agent&#x27;</span>] = <span class="string">&#x27;JDipone/164880 (iphone; ios 12.1.2; Scale/2.00)&#x27;</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            request.headersp[<span class="string">&#x27;user-agent&#x27;</span>] = random.choice(User_Agent)</span><br></pre></td></tr></table></figure>



<p>2.实现代理IP中间件</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">实现代理IP中间件</span></span><br><span class="line"><span class="string">步骤:</span></span><br><span class="line"><span class="string">    。在middlewares.py中, 实现ProxyMiddleware类</span></span><br><span class="line"><span class="string">    。实现process_request方法</span></span><br><span class="line"><span class="string">        从代理池中获取一个随机的代理IP,需指定代理IP的协议，和访问的域名</span></span><br><span class="line"><span class="string">        设置给request.meta[&#x27;proxy&#x27;]</span></span><br><span class="line"><span class="string">    。实现 process_exception 方法</span></span><br><span class="line"><span class="string">        当请求出现异常的时候,代理池哪些代理IP在本域名下是不可以用的</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 异常类型</span></span><br><span class="line"><span class="keyword">from</span> scrapy.downloadermiddlewares.retry <span class="keyword">import</span> RetryMiddleware</span><br><span class="line"><span class="keyword">from</span> twisted.internet <span class="keyword">import</span> defer</span><br><span class="line"><span class="keyword">from</span> twisted.internet.error <span class="keyword">import</span> (</span><br><span class="line">    ConnectError,</span><br><span class="line">    ConnectionDone,</span><br><span class="line">    ConnectionLost,</span><br><span class="line">    ConnectionRefusedError,</span><br><span class="line">    DNSLookupError,</span><br><span class="line">    TCPTimedOutError,</span><br><span class="line">    TimeoutError,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> twisted.web.client <span class="keyword">import</span> ResponseFailed</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapy.core.downloader.handlers.http11 <span class="keyword">import</span> TunnelError</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ProxyMiddleware</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    EXCEPTIONS_TO_RETRY = (defer.TimeoutError, TimeoutError, DNSLookupError,</span><br><span class="line">                           ConnectionRefusedError, ConnectionDone, ConnectError,</span><br><span class="line">                           ConnectionLost, TCPTimedOutError, ResponseFailed,</span><br><span class="line">                           IOError, TunnelError)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span>(<span class="params">self, request, spider</span>):</span></span><br><span class="line">        response = requests.get(<span class="string">&#x27;http://localhoat:6868/random?protocol=https&amp;domain=jd.com&#x27;</span>)</span><br><span class="line">        request.meta[<span class="string">&#x27;proxy&#x27;</span>] = response.content.decode()</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_exception</span>(<span class="params">self, request, exception, spider</span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(exception,self.EXCEPTIONS_TO_RETRY):</span><br><span class="line">            url = <span class="string">&#x27;http://localhoat:6868/disable_domain&#x27;</span></span><br><span class="line">            proxy = request.meta[<span class="string">&#x27;proxy&#x27;</span>]</span><br><span class="line">            ip  = re.findall(<span class="string">&#x27;https?://(.+?):\d+&#x27;</span>,proxy)[<span class="number">0</span>]</span><br><span class="line">            params =&#123;</span><br><span class="line">                <span class="string">&#x27;ip&#x27;</span> : ip,</span><br><span class="line">                <span class="string">&#x27;domain&#x27;</span>:<span class="string">&#x27;jd.com&#x27;</span></span><br><span class="line">            &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>




<p>3.在settings.py 文件开启,下载器中间件</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Enable or disable downloader middlewares</span></span><br><span class="line"><span class="comment"># See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html</span></span><br><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">    <span class="string">&#x27;mall_spider.middlewares.ProxyMiddleware&#x27;</span>: <span class="number">300</span>,</span><br><span class="line">    <span class="string">&#x27;mall_spider.middlewares.RandomUserAgent&#x27;</span>: <span class="number">301</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://maolululu.github.io/maolu.github.io/2021/04/24/pythonSpies/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/maolu.github.io/images/toux.gif">
      <meta itemprop="name" content="maolu">
      <meta itemprop="description" content="Happy Coding">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="maolu">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/maolu.github.io/2021/04/24/pythonSpies/" class="post-title-link" itemprop="url">pythonSpies</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-04-24 15:18:50" itemprop="dateCreated datePublished" datetime="2021-04-24T15:18:50+08:00">2021-04-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-04-29 00:05:38" itemprop="dateModified" datetime="2021-04-29T00:05:38+08:00">2021-04-29</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>#————————- 代理池————————-</p>
<h3 id="什么是代理池"><a href="#什么是代理池" class="headerlink" title="什么是代理池"></a>什么是代理池</h3><p>​    由代理IP组成的池子,它可以提供多个稳定可用的代理IP</p>
<h3 id="为什么要实现代理池"><a href="#为什么要实现代理池" class="headerlink" title="为什么要实现代理池"></a>为什么要实现代理池</h3><p>​    从—堆不稳定代理IP中,抽取高可用代理IP给爬虫使用</p>
<h3 id="代理池开发环境"><a href="#代理池开发环境" class="headerlink" title="代理池开发环境"></a>代理池开发环境</h3><p>​    开发语言:Python3。主要技术:requests lxml pymongo Flask</p>
<h3 id="代理池的设计"><a href="#代理池的设计" class="headerlink" title="代理池的设计"></a>代理池的设计</h3><h3 id="代理池工作流程文字描述"><a href="#代理池工作流程文字描述" class="headerlink" title="代理池工作流程文字描述:"></a>代理池工作流程文字描述:</h3><p>​    代理IP采集模块-&gt;采集代理IP-&gt;检测代理IP-&gt;如果不可用用,直接过滤掉,如果可用,指定默认分数-&gt;存入数据库中   </p>
<p>​        代理P检测模块-&gt;从数据库中获取所有代理IP-&gt;检测代理IP→如果代理IP不可用用,就把分数-1,如果分数为0从数据库中删除,否则更新            数据库,如果代理IP可用,恢复为默认分值,更新数据库   </p>
<p>​        代理API模块-&gt;从数据库中选取高可用的代理IP给爬虫使用;</p>
<h3 id="代理池的模块及其作用"><a href="#代理池的模块及其作用" class="headerlink" title="代理池的模块及其作用"></a>代理池的模块及其作用</h3><h4 id="代理池分五大核心模块"><a href="#代理池分五大核心模块" class="headerlink" title="代理池分五大核心模块:"></a>代理池分五大核心模块:</h4><h5 id="爬虫模块"><a href="#爬虫模块" class="headerlink" title="爬虫模块:"></a>爬虫模块:</h5><p>​              采集代理IP-从代理IP网站上采集代理IP·进行校验(获取代理响应速度,协议类型,匿名类型),·把可用代理IP存储到数据库中     </p>
<h5 id="代理IP的校验模块"><a href="#代理IP的校验模块" class="headerlink" title="代理IP的校验模块:"></a>代理IP的校验模块:</h5><p>​      获取指定代理的响应速度,支持的协议以及匿名程度<br>      原因:网站上所标注的响应速度,协议类型和匿名类型是不准确的这里使用httpbin.org进行检测     </p>
<h5 id="数据库模块"><a href="#数据库模块" class="headerlink" title="数据库模块:"></a>数据库模块:</h5><p>​              实现对代理IP的增删改查操作这里使用MongoDB来存储代理IP    </p>
<h5 id="检测模块"><a href="#检测模块" class="headerlink" title="检测模块:"></a>检测模块:</h5><p>​              定时的对代理池中代理进行检测,保证代理池中代理的可用性.-从数据库读取所有的代理IP.对代理IP进行逐一检测,可用开启多个协程,以提高检测速度·如果该代理不可用,就让这个代理分数-1,,当代理的分数到0了,就删除该代理;如果检测到代理可用就恢复为满分.          </p>
<h5 id="代理P服务接口"><a href="#代理P服务接口" class="headerlink" title="代理P服务接口:"></a>代理P服务接口:</h5><p>​              提供高可用的代理IP给爬虫使用代理iP服务接口:提供高可用的代理IP给爬虫使用</p>
<p>​            根据协议类型和域名获取随机的高质量代理IP根据协议类型和域名获取多个高质量代理IP</p>
<p>​            根据代理IP不可用域名,告诉代理池这个代理IP在该域名下不可用,下次获取这个域名的代理IP时候,就不会再获取这个代理P了,从而保证代理P高可用性.</p>
<h5 id="代理池的其他模块"><a href="#代理池的其他模块" class="headerlink" title="代理池的其他模块"></a>代理池的其他模块</h5><p>​             数据模型: domain. py :</p>
<p>​            ·代理IP的数据模型,用于封装代理IP相关信息,比如ip,端口号,响应速度,协议类型,匿名类型,分数等.</p>
<p>​            程序启动入口:main.py</p>
<p>​            提供一个统一的启动入口 </p>
<h5 id="工具模块"><a href="#工具模块" class="headerlink" title="工具模块:"></a>工具模块:</h5><p>​            日志模块:用于记录日志信息</p>
<p>​            http模块:用于获取随机user-Agent的请求头。    </p>
<pre><code>        配置文件: settings.py
  
              用于默认代理的分数,配置日志格式,文件,启动的爬虫,检验的间隔时间等.
</code></pre>
<h5 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h5><p>  – IPProxyPool</p>
<pre><code>  ​   -- core
  
  ​       -- db
  
  ​        -- __init__.py
  
                -- mongo_pool.py
  
  ​        -- proxy_validate
  
  ​               -- __init__.py
  
  ​               -- httpbin_validator.py
  
  ​    -- proxy_spider
  
  ​               -- __init__.py
  
  ​               -- base_spider.py       
  
  ​           -- proxy_spiders.py
  
  ​               -- run_spiders.py
  
  ​         -- proxy_test.py
  
  ​         -- proxy_api.py
  
  ​         -- domain.py
  
  ​         -- utils
  
  ​               -- __init__.py
  
  ​               -- http.py
  
  ​               -- log.py
  
  ​            -- main.py
  
  ​           -- settings.py
</code></pre>
<h3 id="实现代理的思路"><a href="#实现代理的思路" class="headerlink" title="实现代理的思路"></a>实现代理的思路</h3><h4 id="实现项目思路"><a href="#实现项目思路" class="headerlink" title="实现项目思路:"></a>实现项目思路:</h4><p>​先实现基础模块,这些模块不依赖于其他的模块.比如这里:数据模型,校验模块,数据库模块。然后实现具体的功能模块,比如爬虫模块,检测模块,代理API模块</p>
<h3 id="实现代理ip的模型类"><a href="#实现代理ip的模型类" class="headerlink" title="实现代理ip的模型类"></a>实现代理ip的模型类</h3><h4 id="步骤∶"><a href="#步骤∶" class="headerlink" title="步骤∶"></a>步骤∶</h4><ol>
<li><p>定义 Proxy类,继承object</p>
</li>
<li><p>实现__init___方法,负责初始化,包含如下字段:</p>
<p> ip:                代理的IP地址<br>port:            代理IP的端口号<br>protocol:    代理IP支持的协议类型,http是0, https是1, https和http都支持是2nick_type:代理IP的匿名程度,高匿:0。匿名:1,透明:2<br>speed:        代理IP的响应速度,单位s<br>area:           代理IP所在地区<br>score:         代理IP的评分,用于衡量代理的可用性;默认分值可以通过配置文件进行配置.在进行代理可用性检查的时候,每遇到一次请求失败就减1份,减到0的时候从                    池中删除.如果检查代理可用,就恢复默认分值</p>
<p>disable_domains:            不可用域名列表,有些代理IP在某些域名下不可用,但是在其他域名下可用。在配置文件: settings.py中定义MAX_SCORE = 50,表示代理                                            IP的默认最高分数</p>
<p>提供__str__方法,返回数据字符串</p>
</li>
</ol>
<h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">proxy</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,ip,port,protocol=-<span class="number">1</span>,nick_type =-<span class="number">1</span>,speed = -<span class="number">1</span>,area = <span class="literal">None</span>,score=MAX_SCORE,disable_domains=[]</span>):</span></span><br><span class="line">        <span class="comment">#ip: 代理的IP地址</span></span><br><span class="line">        self.ip = ip</span><br><span class="line">        <span class="comment">#port: 代理IP的端口号</span></span><br><span class="line">        self.port = port</span><br><span class="line">        <span class="comment">#protocol: 代理IP支持的协议类型, http是0, https是1, https和http都支持是2</span></span><br><span class="line">        self.protocol = protocol</span><br><span class="line"></span><br><span class="line">        <span class="comment">#nick_type: 代理IP的匿名程度, 高匿: 0。匿名: 1,透明: 2</span></span><br><span class="line">        self.nick_type = nick_type</span><br><span class="line"></span><br><span class="line">        <span class="comment">#speed: 代理IP的响应速度, 单位s</span></span><br><span class="line">        self.speed =speed</span><br><span class="line"></span><br><span class="line">        <span class="comment">#area: 代理IP所在地区</span></span><br><span class="line">        self.area = area</span><br><span class="line">        <span class="comment">#score: 代理IP的评分, 用于衡量代理的可用性; 在配置文件: settings.py中定义MAX_SCORE = 50, 表示代理IP的默认最高分数</span></span><br><span class="line">        <span class="comment">#默认分值可以通过配置文件进行配置.</span></span><br><span class="line">        <span class="comment">#在进行代理可用性检查的时候, 每遇到一次请求失败就减1份, 减到0的时候从池中删除.</span></span><br><span class="line">        <span class="comment">#如果检查代理可用, 就恢复默认分值</span></span><br><span class="line">        self.score = score</span><br><span class="line"></span><br><span class="line">        <span class="comment">#disable_domains: 不可用域名列表, 有些代理IP在某些域名下不可用, 但是在其他域名下可用。</span></span><br><span class="line">        self.disable_domains = disable_domains</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span>  <span class="built_in">str</span>(self.__dict__)</span><br></pre></td></tr></table></figure>



<h3 id="实现代理ip的工具类"><a href="#实现代理ip的工具类" class="headerlink" title="实现代理ip的工具类"></a>实现代理ip的工具类</h3><h4 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h4><ol>
<li>实现日志模块</li>
<li> http模块</li>
</ol>
<h4 id="日志模块"><a href="#日志模块" class="headerlink" title="日志模块"></a>日志模块</h4><h4 id="1-目的"><a href="#1-目的" class="headerlink" title="1. 目的"></a>1. 目的</h4><p>能够方便的对程序进行调试<br>能够方便记录程序的运行状态·能够方便记录错误信息</p>
<h4 id="2-日志的实现"><a href="#2-日志的实现" class="headerlink" title="2. 日志的实现"></a>2. 日志的实现</h4><h5 id="步骤-1"><a href="#步骤-1" class="headerlink" title="步骤"></a>步骤</h5><ol>
<li>拷贝笔记日志代码到项目中</li>
<li>把日志相关配置信息放到配置文件中。修改日志代码,使用配置文件中的配置信息</li>
<li>修改日志代码,使用配置文件的配置信息</li>
</ol>
<h5 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 日志配置信息</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">LOG_LEVEL = logging.INFO   <span class="comment">#默认等级</span></span><br><span class="line"></span><br><span class="line">LOG_FMT = <span class="string">&#x27;%(asctime)s %(filename)s [line:%(lineno)d] %(levelname)s:%(message)s&#x27;</span></span><br><span class="line"></span><br><span class="line">LOG_DATEFMT = <span class="string">&#x27;%Y-%m-%d %H: %M:%S&#x27;</span>  <span class="comment">#默认时间格式</span></span><br><span class="line"></span><br><span class="line">LOG_FILENAME =<span class="string">&#x27;log.log&#x27;</span>   <span class="comment">#默认日志文件名称</span></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> settings <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Logger</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>) :</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">#1 获取—个logger对象</span></span><br><span class="line"></span><br><span class="line">      self._logger =logging.getLogger()</span><br><span class="line"></span><br><span class="line">      <span class="comment">#2 设置format对象</span></span><br><span class="line"></span><br><span class="line">      self.formatter = logging.Formatter(fmt=LOG_FMT,datefmt=LOG_DATEFMT)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># 3设置日志输出</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">#3.1设置文件日志模式</span></span><br><span class="line"></span><br><span class="line">      self._logger.addHandler(self._get_file_handler(LOG_FILENAME))</span><br><span class="line"></span><br><span class="line">      <span class="comment">#3.2设置终端日志模式</span></span><br><span class="line"></span><br><span class="line">      self._logger.addHandler(self._get_console_handler())</span><br><span class="line"></span><br><span class="line">     <span class="comment">#4.设置日志等级</span></span><br><span class="line"></span><br><span class="line">      self._logger.setLevel( LOG_LEVEL)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_get_file_handler</span>(<span class="params">self, filename</span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#返向一个文件日志handler</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 1。获取一个文件日志handler</span></span><br><span class="line"></span><br><span class="line">        filehandler = logging.FileHandler(filename=filename, encoding=<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2.设置日志格式</span></span><br><span class="line"></span><br><span class="line">        filehandler.setFormatter(self.formatter)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3。返回</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> filehandler</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_get_console_handler</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#返回—个输出到终端白志handler</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#1获取一个输出到终端日志handler</span></span><br><span class="line"></span><br><span class="line">        console_handler = logging.StreamHandler(sys.stdout)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2。设置日志格式</span></span><br><span class="line"></span><br><span class="line">        console_handler.setFormatter(self.formatter)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3. 返回handler</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> console_handler</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="meta">  @property</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">logger</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> self._logger</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化并配一个logger对象,达到单例的# 使用时,直接导入logger就可以使用</span></span><br><span class="line"></span><br><span class="line">logger= Logger().logger</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    logger.debug(<span class="string">&quot;调试信息&quot;</span>)</span><br><span class="line"></span><br><span class="line">    logger.info(<span class="string">&quot;状态信息&quot;</span>)</span><br><span class="line"></span><br><span class="line">    logger.warning(<span class="string">&quot;警告信息&quot;</span>)</span><br><span class="line"></span><br><span class="line">    logger.error(<span class="string">&quot;错误信息&quot;</span>)</span><br><span class="line"></span><br><span class="line">    logger.critical(<span class="string">&quot;严重错误信息&quot;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="http模块"><a href="#http模块" class="headerlink" title="http模块"></a>http模块</h4><p>提供随机的User-Agent请求头, 为了不容易不服务器识别为是一个爬虫<br>目标..获取随机User-Agent的请求头<br>步骤∶<br>    1.准备User-Agent的列表<br>    2.实现一个方法,获取随机User-Agent的请求头</p>
<h5 id="代码-2"><a href="#代码-2" class="headerlink" title="代码"></a>代码</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random </span><br><span class="line"></span><br><span class="line">USER_AGENTS = [</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; AcooBrowser; .NET CLR 1.1.4322; .NET CLR 2.0.50727)&quot;</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0; Acoo Browser; SLCC1; .NET CLR 2.0.50727; Media Center PC 5.0; .NET CLR 3.0.04506)&quot;</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;Mozilla/4.0 (compatible; MSIE 7.0; AOL 9.5; AOLBuild 4337.35; Windows NT 5.1; .NET CLR 1.1.4322; .NET CLR 2.0.50727)&quot;</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;Mozilla/5.0 (Windows; U; MSIE 9.0; Windows NT 9.0; en-US)&quot;</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 2.0.50727; Media Center PC 6.0)&quot;</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 1.0.3705; .NET CLR 1.1.4322)&quot;</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;Mozilla/4.0 (compatible; MSIE 7.0b; Windows NT 5.2; .NET CLR 1.1.4322; .NET CLR 2.0.50727; InfoPath.2; .NET CLR 3.0.04506.30)&quot;</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN) AppleWebKit/523.15 (KHTML, like Gecko, Safari/419.3) Arora/0.3 (Change: 287 c9dfb30)&quot;</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;Mozilla/5.0 (X11; U; Linux; en-US) AppleWebKit/527+ (KHTML, like Gecko, Safari/419.3) Arora/0.6&quot;</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.2pre) Gecko/20070215 K-Ninja/2.1.1&quot;</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN; rv:1.9) Gecko/20080705 Firefox/3.0 Kapiko/3.0&quot;</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;Mozilla/5.0 (X11; Linux i686; U;) Gecko/20070322 Kazehakase/0.4.5&quot;</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.8) Gecko Fedora/1.9.0.8-1.fc10 Kazehakase/0.5.6&quot;</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11&quot;</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_3) AppleWebKit/535.20 (KHTML, like Gecko) Chrome/19.0.1036.7 Safari/535.20&quot;</span>,</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;Opera/9.80 (Macintosh; Intel Mac OS X 10.6.8; U; fr) Presto/2.9.168 Version/11.52&quot;</span>,]</span><br><span class="line"></span><br><span class="line">  <span class="comment">#实现一个方法,获取随机User-Agent的请求头def get_request_headers ( ) :</span></span><br><span class="line"></span><br><span class="line">   headers = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span> : random.choice(USER_AGENTS),</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;Accept &#x27;</span> : <span class="string">&#x27;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#x27;</span>,</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;Accept-Language &#x27;</span> : <span class="string">&#x27;en-us , en;q=0.5&#x27;</span>,</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;connection &#x27;</span> : <span class="string">&#x27;keep-alive&#x27;</span>,</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;Accept-Encoding&#x27;</span> : <span class="string">&#x27;gzip, deflate &#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">return</span> headers</span><br></pre></td></tr></table></figure>





<h3 id="实现代理ip的校验模块"><a href="#实现代理ip的校验模块" class="headerlink" title="实现代理ip的校验模块"></a>实现代理ip的校验模块</h3><h4 id="目标∶"><a href="#目标∶" class="headerlink" title="目标∶"></a>目标∶</h4><p> 检查代理IP速度,匿名程度以及支持的协议类型.</p>
<h4 id="步骤-2"><a href="#步骤-2" class="headerlink" title="步骤"></a>步骤</h4><h5 id="检查代理IP速度和匿名程度"><a href="#检查代理IP速度和匿名程度" class="headerlink" title="检查代理IP速度和匿名程度"></a>检查代理IP速度和匿名程度</h5><h6 id="代理IP速度"><a href="#代理IP速度" class="headerlink" title="代理IP速度:"></a>代理IP速度:</h6><p>​        从发送请求到获取响应的时间间隔</p>
<h6 id="匿名程度检查"><a href="#匿名程度检查" class="headerlink" title="匿名程度检查:"></a>匿名程度检查:</h6><p> 对http: / /httpbin.org/get 或 https : / /httpbin.org/get发送请求</p>
<pre><code>     如果响应的origin中有‘ ; &#39;分割的两个IP就是透明代理IP
 
     如果响应的headers中包含 Proxy-Connection 说明是匿名代理IP-否则就是高匿代理IP
</code></pre>
<h5 id="检查代理IP协议类型"><a href="#检查代理IP协议类型" class="headerlink" title="检查代理IP协议类型"></a>检查代理IP协议类型</h5><p>​    如果http: / /httpbin.org/get发送请求可以成功,说明支持http协议</p>
<p>​    如果https : / / httpbin.org/get发送请求可以成功,说明支持https协议</p>
<h4 id="代码-3"><a href="#代码-3" class="headerlink" title="代码:"></a>代码:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jsonimport timeimport requests</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> utils.http <span class="keyword">import</span> get_request_headersfrom settings <span class="keyword">import</span> TEST_TIMEOUTfrom utils.log <span class="keyword">import</span> loggerfrom domain <span class="keyword">import</span> Proxy</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check_proxy</span>(<span class="params">proxy</span>):</span></span><br><span class="line"></span><br><span class="line">  <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  用于检查指定代理ip的响应速度,匿名程度,支持的协议</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  :param proxy: 代理ip模型对象</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  :return: 检查后的代理ip模型对象</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">#代理ip字典</span></span><br><span class="line"></span><br><span class="line">  proxies = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;http&#x27;</span>:<span class="string">&#x27;http://&#123;&#125;:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(proxy.ip,proxy.port),</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;https&#x27;</span>:<span class="string">&#x27;https://&#123;&#125;:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(proxy.ip,proxy.port)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">#测试代理ip</span></span><br><span class="line"></span><br><span class="line">  http, http_nick_type,http_speed = _check_http_proxies(proxies)</span><br><span class="line"></span><br><span class="line">  https, https_nick_type,https_speed = _check_http_proxies(proxies,<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">#代理ip支持的协议类型</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># protocol: 代理IP支持的协议类型, http是0, https是1, https和http都支持是2</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> http <span class="keyword">and</span> https:</span><br><span class="line"></span><br><span class="line">    proxy.protocol = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    proxy.speed = http_speed</span><br><span class="line"></span><br><span class="line">    proxy.nick_type = http_nick_type</span><br><span class="line"></span><br><span class="line">  <span class="keyword">elif</span> http:</span><br><span class="line"></span><br><span class="line">    proxy.protocol = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    proxy.speed = http_speed</span><br><span class="line"></span><br><span class="line">    proxy.nick_type = http_nick_type</span><br><span class="line"></span><br><span class="line">  <span class="keyword">elif</span> https:</span><br><span class="line"></span><br><span class="line">    proxy.protocol = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    proxy.speed = https_speed</span><br><span class="line"></span><br><span class="line">    proxy.nick_type = https_nick_type</span><br><span class="line"></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">    proxy.protocol = -<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    proxy.speed = -<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    proxy.nick_type = -<span class="number">1</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> proxy</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_check_http_proxies</span>(<span class="params">proxies,is_http = <span class="literal">True</span></span>):</span></span><br><span class="line"> </span><br><span class="line">  nick_type = -<span class="number">1</span></span><br><span class="line"></span><br><span class="line">  speed = -<span class="number">1</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> is_http :</span><br><span class="line"></span><br><span class="line">    test_url = <span class="string">&#x27;http://httpbin.org/get&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">    test_url = <span class="string">&#x27;https://httpbin.org/get&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">try</span>:</span><br><span class="line"></span><br><span class="line">    <span class="comment">#获取开始测试时间</span></span><br><span class="line"></span><br><span class="line">    start = time.time()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#发送请求获取响应数据</span></span><br><span class="line"></span><br><span class="line">    respone = requests.get(test_url,headers = get_request_headers(),proxies = proxies,timeout = TEST_TIMEOUT)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> respone.ok :</span><br><span class="line"></span><br><span class="line">      <span class="comment">#响应成功 ,计算响应速度</span></span><br><span class="line"></span><br><span class="line">      speed = <span class="built_in">round</span>(time.time()  - start , <span class="number">2</span>) </span><br><span class="line"></span><br><span class="line">      <span class="comment">#检测匿名程度 </span></span><br><span class="line"></span><br><span class="line">      <span class="comment">#把响应的json ,转换为字典</span></span><br><span class="line"></span><br><span class="line">      dic = json.loads(respone.text)</span><br><span class="line"></span><br><span class="line">      <span class="comment">#获取来源ip  origin</span></span><br><span class="line"></span><br><span class="line">      origin = dic[<span class="string">&#x27;origin&#x27;</span>]</span><br><span class="line"></span><br><span class="line">      proxy_connection = dic[<span class="string">&#x27;headers&#x27;</span>].get(<span class="string">&#x27;Proxy-Connection&#x27;</span>,<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">      <span class="comment">#-如果响应的 origin 中有‘ ; &#x27;分割的两个IP就是透明代理IP</span></span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> <span class="string">&#x27;,&#x27;</span><span class="keyword">in</span> origin :</span><br><span class="line"></span><br><span class="line">        nick_type = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">      <span class="comment"># 如果响应的 headers中包含 Proxy-Connection 说明是匿名代理IP-否则就是高匿代理IP</span></span><br><span class="line"></span><br><span class="line">      <span class="keyword">elif</span> proxy_connection :</span><br><span class="line"></span><br><span class="line">        nick_type = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">      <span class="keyword">else</span> :</span><br><span class="line"></span><br><span class="line">         nick_type = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">      <span class="keyword">return</span> <span class="literal">True</span>,nick_type,speed</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span>,nick_type,speed</span><br><span class="line"></span><br><span class="line">  <span class="keyword">except</span> Exception <span class="keyword">as</span> ex:</span><br><span class="line"></span><br><span class="line">    <span class="comment">#logger.exception(ex)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span>,nick_type,speed</span><br></pre></td></tr></table></figure>





<h3 id="实现数据库模块"><a href="#实现数据库模块" class="headerlink" title="实现数据库模块"></a>实现数据库模块</h3><h4 id="作用"><a href="#作用" class="headerlink" title="作用:"></a>作用:</h4><p> 用于对proxies集合进行数据库的相关操作</p>
<h4 id="目标"><a href="#目标" class="headerlink" title="目标:"></a>目标:</h4><p> 实现对数据库增删改查相关操作</p>
<h4 id="步骤-3"><a href="#步骤-3" class="headerlink" title="步骤:"></a>步骤:</h4><h5 id="1-在-init-中-建立数据连接-获取要操作的集合-在del方法中关闭数据库连接"><a href="#1-在-init-中-建立数据连接-获取要操作的集合-在del方法中关闭数据库连接" class="headerlink" title="1. 在 init 中,建立数据连接,获取要操作的集合,在del方法中关闭数据库连接"></a>1. 在 init 中,建立数据连接,获取要操作的集合,在del方法中关闭数据库连接</h5><h5 id="2-提供基础的增删改查功能"><a href="#2-提供基础的增删改查功能" class="headerlink" title="2. 提供基础的增删改查功能"></a>2. 提供基础的增删改查功能</h5><p>​    i.实现插入功能</p>
<p>​    ii,实现修改该功能</p>
<p>​    iii.实现删除代理:根据代理的IP制除代理</p>
<p>​    iv.查询所有代理IP的功能 </p>
<h4 id="3-提供代理AP模块使用的功能"><a href="#3-提供代理AP模块使用的功能" class="headerlink" title="3.提供代理AP模块使用的功能"></a>3.提供代理AP模块使用的功能</h4><p>i.实现查询功能:根据条件进行查询,可以指定查询数量,先分数降序,速度升序排,保证优质的代理lIP在上面.</p>
<p>ii.实现根据协议类型和要访问网站的域名,获取代理lP列表</p>
<p>iii.实现根据协议类型和要访问网站的域名,随机获取一个代理IP</p>
<p>iv.实现把指定域名添加到指定IP的disable_domain列表中. </p>
<h4 id="代码-4"><a href="#代码-4" class="headerlink" title="代码"></a>代码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pymongoimport random</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pymongo <span class="keyword">import</span> MongoClientfrom settings <span class="keyword">import</span> MONDODB_URLfrom utils.log <span class="keyword">import</span> loggerfrom domain <span class="keyword">import</span> Proxy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MongoPool</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">#1.在 init 中,建立数据连接,获取要操作的集合,在del方法中关闭数据库连接</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">​    <span class="comment">#建立数据库连接</span></span><br><span class="line"></span><br><span class="line">​    self.client = MongoClient(MONDODB_URL)</span><br><span class="line"></span><br><span class="line">​    <span class="comment">#获取要操作的集合</span></span><br><span class="line"></span><br><span class="line">​    self.proxies = self.client[<span class="string">&#x27;proxies_pool&#x27;</span>][<span class="string">&#x27;proxies&#x27;</span>]  <span class="comment">#数据库名,集合</span></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__del__</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">​    self.client.close()</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment">#2.提供基础的增删改查功能 *</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 实现插入功能</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">insert_one</span>(<span class="params">self,proxy</span>):</span></span><br><span class="line"></span><br><span class="line">​    count = self.proxies.count_documents(&#123;<span class="string">&#x27;_id&#x27;</span>: proxy.ip&#125;)</span><br><span class="line"></span><br><span class="line">​    <span class="keyword">if</span> count==<span class="number">0</span>:</span><br><span class="line"></span><br><span class="line">​      <span class="comment">#proxy.ip 作为 mongodb中数据的主键 _id</span></span><br><span class="line"></span><br><span class="line">​      dic = proxy.__dict__</span><br><span class="line"></span><br><span class="line">​      dic[<span class="string">&#x27;_id&#x27;</span>] = proxy.ip</span><br><span class="line"></span><br><span class="line">​      self.proxies.insert_one(dic)</span><br><span class="line"></span><br><span class="line">​      logger.info(<span class="string">&#x27;插入新的代理:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(proxy))</span><br><span class="line"></span><br><span class="line">​    <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">​      logger.warning(<span class="string">&#x27;已经存在的代理:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(proxy))</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment"># 实现修改该功能</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">update_one</span>(<span class="params">self,proxy</span>):</span></span><br><span class="line"></span><br><span class="line">​    self.proxies.update_one(&#123;<span class="string">&#x27;_id&#x27;</span>:proxy.ip&#125;, &#123;<span class="string">&#x27;$set&#x27;</span>: proxy.__dict__&#125;)</span><br><span class="line"></span><br><span class="line">​    logger.info(<span class="string">&#x27;更新代理:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(proxy))</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment"># 实现删除代理: 根据代理的IP删除代理iv.查询所有代理IP的功能</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">delect_one</span>(<span class="params">self,proxy</span>):</span></span><br><span class="line"></span><br><span class="line">​    self.proxies.delete_one(&#123;<span class="string">&#x27;_id&#x27;</span>:proxy.ip&#125;)</span><br><span class="line"></span><br><span class="line">​    logger.info(<span class="string">&#x27;删除代理:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(proxy))</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment"># 查找所有的代理ip</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">find_all</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">​    cursor = self.proxies.find()</span><br><span class="line"></span><br><span class="line">​    <span class="keyword">for</span> item <span class="keyword">in</span> cursor:</span><br><span class="line"></span><br><span class="line">​      <span class="comment">#Proxy 没有 ‘_id ’字段 所有要删除</span></span><br><span class="line"></span><br><span class="line">​      item.pop(<span class="string">&#x27;_id&#x27;</span>)</span><br><span class="line"></span><br><span class="line">​      proxy = Proxy(**item)</span><br><span class="line"></span><br><span class="line">​      <span class="keyword">yield</span> proxy</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  3.提供代理API模块使用的功能</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    i.实现查询功能:根据条件进行查询,可以指定查询数量,先分数降序,速度升序排,保证优质的代理IP在上面.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    ii.实现根据协议类型和要访问网站的域名,获取代理IP列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    iii.实现根据协议类型和要访问完整的域名,随机获取一个代理IP</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    iiii.实现把指定域名添加到指定IP的disable_domain列表中.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">find</span>(<span class="params">self,conditions=&#123;&#125;,count = <span class="number">0</span></span>):</span></span><br><span class="line"></span><br><span class="line">​    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    实现查询功能:根据条件进行查询,可以指定查询数量,先分数降序,速度升序排,保证优质的代理IP在上面.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    :param conditions: 查询条件字典</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    :param count:  限制最多取出多少个代理ip</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    :return:   返回满足要求的(proxy)对象列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">​    cursor=self.proxies.find(conditions,limit=count).sort(</span><br><span class="line"></span><br><span class="line">​      [(<span class="string">&#x27;score&#x27;</span>, pymongo.DESCENDING),(<span class="string">&#x27;speed&#x27;</span>,pymongo.ASCENDING)]</span><br><span class="line"></span><br><span class="line">​    )</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​    <span class="comment"># 准备列表 用来存储查询到的proxy</span></span><br><span class="line"></span><br><span class="line">​    proxy_list = []</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​    <span class="comment"># 遍历 cursor</span></span><br><span class="line"></span><br><span class="line">​    <span class="keyword">for</span> item <span class="keyword">in</span> cursor:</span><br><span class="line"></span><br><span class="line">​      item.pop(<span class="string">&#x27;_id&#x27;</span>)</span><br><span class="line"></span><br><span class="line">​      proxy = Proxy(**item)</span><br><span class="line"></span><br><span class="line">​      proxy_list.append(proxy)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​    <span class="keyword">return</span> proxy_list</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">get_proxies</span>(<span class="params">self,protocol = <span class="literal">None</span>,domain =<span class="literal">None</span>,count = <span class="number">0</span>,nick_type = <span class="number">0</span></span>):</span></span><br><span class="line"></span><br><span class="line">​    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    ii.实现根据协议类型和要访问网站的域名,获取代理IP列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    :param protocol:  协议: http , https</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    :param domain:   域名 taobao.com</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    :param count:   用于限制获取多个代理ip 默认为所有</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    :param nick_type:  匿名程度 默认 高匿</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    :return:      满足要求的代理ip</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    &#x27;&#x27;&#x27;</span></span><br><span class="line">​    <span class="comment">#定义查询条件</span></span><br><span class="line"></span><br><span class="line">​    condition = &#123;<span class="string">&#x27;nick_type&#x27;</span>:nick_type&#125;</span><br><span class="line"></span><br><span class="line">​    <span class="comment"># 根据协议类型 指定查询条件</span></span><br><span class="line"></span><br><span class="line">​    <span class="keyword">if</span> protocol <span class="keyword">is</span> <span class="literal">None</span> :</span><br><span class="line"></span><br><span class="line">​      <span class="comment"># 返回支持http 和 https 的代理ip</span></span><br><span class="line"></span><br><span class="line">​      condition[<span class="string">&#x27;protocol&#x27;</span>] = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">​    <span class="keyword">elif</span> protocol.lower() == <span class="string">&#x27;http&#x27;</span>:</span><br><span class="line">​      condition[<span class="string">&#x27;protocol&#x27;</span>] = &#123;<span class="string">&#x27;$in&#x27;</span>:[<span class="number">0</span>,<span class="number">2</span>]&#125;</span><br><span class="line"></span><br><span class="line">​    <span class="keyword">else</span>:</span><br><span class="line">​       condition[<span class="string">&#x27;protocol&#x27;</span>] = &#123;<span class="string">&#x27;$in&#x27;</span>:[<span class="number">1</span>,<span class="number">2</span>]&#125; </span><br><span class="line"></span><br><span class="line">​    <span class="keyword">if</span> domain:</span><br><span class="line">​      condition[<span class="string">&#x27;disable_domain&#x27;</span>] = &#123;<span class="string">&#x27;$nin&#x27;</span>:[domain]&#125;</span><br><span class="line"></span><br><span class="line">​    <span class="keyword">return</span> self.find(condition,count=count)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">random_proxy</span>(<span class="params">self,protocol = <span class="literal">None</span>,domain =<span class="literal">None</span>,count = <span class="number">0</span>,nick_type = <span class="number">0</span></span>):</span></span><br><span class="line"></span><br><span class="line">​    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​     iii.实现根据协议类型和要访问完整的域名,随机获取一个代理IP</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    :param protocol:  协议: http , https</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    :param domain:   域名 taobao.com</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    :param count:   用于限制获取多个代理ip 默认为所有</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    :param nick_type:  匿名程度 默认 高匿</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    :return:      满足一个要求的代理ip</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">​    proxy_list = self.get_proxies(protocol = protocol,domain =domain,count =count ,nick_type = nick_type)</span><br><span class="line"></span><br><span class="line">​    <span class="keyword">return</span> random.choice(proxy_list)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">disable_domain</span>(<span class="params">self,ip,domain</span>):</span></span><br><span class="line"></span><br><span class="line">​    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​      iiii.实现把指定域名添加到指定IP的disable_domain列表中.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    :param ip:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    :param domain:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    :return:  True添加成功 FALSE 添加失败</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​    <span class="comment"># 判断disable_domains 是否已经有 domain</span></span><br><span class="line"></span><br><span class="line">​    <span class="keyword">if</span> self.proxies.count_documents(&#123;<span class="string">&#x27;_id&#x27;</span>:ip,<span class="string">&#x27;disable_domains&#x27;</span>:domain&#125;) ==<span class="number">0</span> :</span><br><span class="line"></span><br><span class="line">​      self.proxies.update_one(&#123;<span class="string">&#x27;_ip&#x27;</span>:ip&#125;,&#123;<span class="string">&#x27;$push&#x27;</span>:&#123;<span class="string">&#x27;disable_domains&#x27;</span>:domain&#125;&#125;)</span><br><span class="line"></span><br><span class="line">​      <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">​    <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">​      <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"> </span><br></pre></td></tr></table></figure>





<h3 id="实现代理ip爬虫模块"><a href="#实现代理ip爬虫模块" class="headerlink" title="实现代理ip爬虫模块"></a>实现代理ip爬虫模块</h3><h4 id="爬虫模块的需求"><a href="#爬虫模块的需求" class="headerlink" title="爬虫模块的需求"></a>爬虫模块的需求</h4><p>​        需求:抓取各个代理IP网站上的免费代理IP,进行检测,如果可用存储到数据库中</p>
<h4 id="需要抓取代理IP的页面如下"><a href="#需要抓取代理IP的页面如下" class="headerlink" title="需要抓取代理IP的页面如下:"></a>需要抓取代理IP的页面如下:</h4><p>​        西刺代理:  <a target="_blank" rel="noopener" href="https://www.xicidaili.com/nn/1">https://www.xicidaili.com/nn/1</a></p>
<p>​        ip3366代理:  http:/ /<a target="_blank" rel="noopener" href="http://www.ip3366.net/free/?stype=1&amp;page=1">www.ip3366.net/free/?stype=1&amp;page=1</a></p>
<p>​        快代理:  <a target="_blank" rel="noopener" href="https://www.kuaidaili.com/free/inha/1">https://www.kuaidaili.com/free/inha/1</a> /</p>
<p>​        proxylistplus代理:  <a target="_blank" rel="noopener" href="https://list.proxylistplus.com/Fresh-HTTP-Proxy-List-166ip%E4%BB%A3%E7%90%86">https://list.proxylistplus.com/Fresh-HTTP-Proxy-List-166ip代理</a>:  <a target="_blank" rel="noopener" href="http://www.66ip.cn/1.htm">http://www.66ip.cn/1.htm</a> </p>
<h3 id="爬虫模块的设计思路"><a href="#爬虫模块的设计思路" class="headerlink" title="爬虫模块的设计思路"></a>爬虫模块的设计思路</h3><h5 id="通用爬虫"><a href="#通用爬虫" class="headerlink" title="通用爬虫:"></a>通用爬虫:</h5><p>通过指定URL列表,分组XPATH和组内XPATH,来提取不同网站的代理IP</p>
<p>原因代理IP网站的页面结构几乎都是Table,页面结构类似</p>
<h5 id="具体爬虫-用于抓取具体代理IP网站"><a href="#具体爬虫-用于抓取具体代理IP网站" class="headerlink" title="具体爬虫:用于抓取具体代理IP网站"></a>具体爬虫:用于抓取具体代理IP网站</h5><p>通过继承通用爬虫实现具体网站的抓取,一般只需要指定爬取的URL列表,分组的XPATH和组内XPATH就可以了.<br>如果该网站有特殊反爬手段,可以通过重写某些方法实现反爬</p>
<h5 id="爬虫运行模块"><a href="#爬虫运行模块" class="headerlink" title="爬虫运行模块:"></a>爬虫运行模块:</h5><h5 id="启动爬虫-抓取代理IP-进行检测-如果可用-就存储到数据库中"><a href="#启动爬虫-抓取代理IP-进行检测-如果可用-就存储到数据库中" class="headerlink" title="启动爬虫,抓取代理IP,进行检测,如果可用,就存储到数据库中;"></a>启动爬虫,抓取代理IP,进行检测,如果可用,就存储到数据库中;</h5><p>通过配置文件来控制启动哪些爬虫,增加扩展性;如果将来我们遇到返回json格式的代理网站,单独写一个爬虫配置下就好了.</p>
<h4 id="实现通用爬虫"><a href="#实现通用爬虫" class="headerlink" title="实现通用爬虫"></a>实现通用爬虫</h4><h5 id="目标-实现可以指定不同URL列表-分组的XPATH和详情的XPATH-从不同页面上提取代理的IP-端口号和区域的通用爬虫"><a href="#目标-实现可以指定不同URL列表-分组的XPATH和详情的XPATH-从不同页面上提取代理的IP-端口号和区域的通用爬虫" class="headerlink" title="目标:  实现可以指定不同URL列表,分组的XPATH和详情的XPATH,从不同页面上提取代理的IP,端口号和区域的通用爬虫;"></a>目标:  实现可以指定不同URL列表,分组的XPATH和详情的XPATH,从不同页面上提取代理的IP,端口号和区域的通用爬虫;</h5><h5 id="步骤-4"><a href="#步骤-4" class="headerlink" title="步骤:"></a>步骤:</h5><h5 id="1-在base-spider-py文件中-定义一个BaseSpider类-继承object·"><a href="#1-在base-spider-py文件中-定义一个BaseSpider类-继承object·" class="headerlink" title="1.在base_spider.py文件中,定义一个BaseSpider类,继承object·"></a>1.在base_spider.py文件中,定义一个BaseSpider类,继承object·</h5><h5 id="2-提供三个类成员变量"><a href="#2-提供三个类成员变量" class="headerlink" title="2.提供三个类成员变量:"></a>2.提供三个类成员变量:</h5><pre><code> urls: 代理IP网址的URL的列表
</code></pre>
<p>​       group_xpath:分组XPATH,获取包含代理IP信息标签列表的XPATH</p>
<pre><code> detail_xpath:组内XPATH,获取代理IP详情的信息XPATH,格式为: &#123;‘ip’; &#39;x , &#39;port&quot;:‘x’,&quot;area&quot;: ‘xx’&#125;
</code></pre>
<h5 id="3-提供初始方法-传入爬虫URL列表-分组XPATH-详情-组内-XPATH"><a href="#3-提供初始方法-传入爬虫URL列表-分组XPATH-详情-组内-XPATH" class="headerlink" title="3.提供初始方法,传入爬虫URL列表,分组XPATH.详情(组内)XPATH"></a>3.提供初始方法,传入爬虫URL列表,分组XPATH.详情(组内)XPATH</h5><h5 id="4-对外提供一个获取代理IP的方法"><a href="#4-对外提供一个获取代理IP的方法" class="headerlink" title="4.对外提供一个获取代理IP的方法"></a>4.对外提供一个获取代理IP的方法</h5><p>遍历URL列表,获取URL<br>根据发送请求,获取页面数据<br>解析页面,提取数据,封装为Proxy对象<br>返回Proxy对象列表</p>
<h4 id="代码-5"><a href="#代码-5" class="headerlink" title="代码"></a>代码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  requests</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> utils.http <span class="keyword">import</span>  get_request_headers</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> domain <span class="keyword">import</span>  Proxy<span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">实现通用爬虫:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  目标:  实现可以指定不同URL列表,分组的XPATH和详情的XPATH,</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​      从不同页面上提取代理的IP,端口号和区域的通用爬虫;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  步骤:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    1.在base_spider.py文件中,定义一个BaseSpider类,继承object</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    2.提供三个类成员变量:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​      urls: 代理IP网址的URL的列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​      group_xpath:分组XPATH,获取包含代理IP信息标签列表的XPATH</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​      detail_xpath:组内XPATH,获取代理IP详情的信息XPATH,格式为: &#123;‘ip’; &#x27;x , &#x27;port&quot;:‘x’,&quot;area&quot;: ‘xx’&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    3.提供初始方法,传入爬虫URL列表,分组XPATH.详情(组内)XPATH</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    4.对外提供一个获取代理IP的方法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​      遍历URL列表,获取URL</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​      根据发送请求,获取页面数据</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​      解析页面,提取数据,封装为Proxy对象</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​      返回Proxy对象列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">base_spider</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># urls: 代理IP网址的URL的列表</span></span><br><span class="line"></span><br><span class="line">  urls = []</span><br><span class="line"></span><br><span class="line">  <span class="comment"># group_xpath: 分组XPATH, 获取包含代理IP信息标签列表的XPATH</span></span><br><span class="line"></span><br><span class="line">  group_xpath = <span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># detail_xpath: 组内XPATH, 获取代理IP详情的信息XPATH, 格式为: &#123;‘ip’; &#x27;x&#x27;, &#x27;port&#x27;:‘x’,&quot;area&quot;: ‘xx’&#125;</span></span><br><span class="line"></span><br><span class="line">  detail_xpath = &#123;&#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment"># 3.提供初始方法,传入爬虫URL列表,分组XPATH.详情(组内)XPATH</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,urls=[],group_xpath=<span class="string">&#x27;&#x27;</span>,detail_xpath = &#123;&#125;</span>):</span></span><br><span class="line"></span><br><span class="line">​    <span class="keyword">if</span> urls :</span><br><span class="line"></span><br><span class="line">​      self.urls = urls</span><br><span class="line"></span><br><span class="line">​    <span class="keyword">if</span> group_xpath :</span><br><span class="line"></span><br><span class="line">​      self.group_xpath = group_xpath</span><br><span class="line"></span><br><span class="line">​    <span class="keyword">if</span> detail_xpath:</span><br><span class="line"></span><br><span class="line">​      self.detail_xpath = detail_xpath</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">get_page_from_url</span>(<span class="params">self,url</span>):</span></span><br><span class="line"></span><br><span class="line">​    reponse = requests.get(url,get_request_headers())</span><br><span class="line"></span><br><span class="line">​    <span class="keyword">return</span> reponse.content</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">get_first_from_list</span>(<span class="params">self,lis</span>):</span></span><br><span class="line"></span><br><span class="line">​    <span class="comment"># 防止IP, prot , area 出现 空</span></span><br><span class="line"></span><br><span class="line">​    <span class="keyword">return</span> lis[<span class="number">0</span>] <span class="keyword">if</span> <span class="built_in">len</span>(lis) !=<span class="number">0</span> <span class="keyword">else</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">get_proxies_from_page</span>(<span class="params">self,page</span>):</span></span><br><span class="line"></span><br><span class="line">​    <span class="comment"># 解析页面 提取数据 封装为 Proxy 对象</span></span><br><span class="line"></span><br><span class="line">​    element = etree.HTML(page)</span><br><span class="line"></span><br><span class="line">​    <span class="comment"># 获取保护ip信息的标签列表</span></span><br><span class="line"></span><br><span class="line">​    trs = element.xpath(self.group_xpath)</span><br><span class="line"></span><br><span class="line">​    <span class="comment"># 遍历trs 获取代理ip相关信息</span></span><br><span class="line"></span><br><span class="line">​    <span class="keyword">for</span> tr <span class="keyword">in</span> trs :</span><br><span class="line"></span><br><span class="line">​      ip = self.get_first_from_list(tr.xpath(self.detail_xpath[<span class="string">&#x27;ip&#x27;</span>]))</span><br><span class="line"></span><br><span class="line">​      port = self.get_first_from_list(tr.xpath(self.detail_xpath[<span class="string">&#x27;port&#x27;</span>]))</span><br><span class="line"></span><br><span class="line">​      area = self.get_first_from_list(tr.xpath(self.detail_xpath[<span class="string">&#x27;area&#x27;</span>]))</span><br><span class="line"></span><br><span class="line">​      proxy = Proxy(ip,port,area = area)</span><br><span class="line"></span><br><span class="line">​      <span class="keyword">yield</span> proxy</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">get_proxies</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">​    <span class="keyword">for</span> url <span class="keyword">in</span> self.urls:</span><br><span class="line"></span><br><span class="line">​      <span class="comment"># 遍历URL列表,获取URL</span></span><br><span class="line"></span><br><span class="line">​      <span class="comment">#根据发送请求,获取页面数据</span></span><br><span class="line"></span><br><span class="line">​      page = self.get_page_from_url(url)</span><br><span class="line"></span><br><span class="line">​      <span class="comment"># 解析页面,提取数据,封装为Proxy对象</span></span><br><span class="line"></span><br><span class="line">​      proxies = self.get_proxies_from_page(page)</span><br><span class="line"></span><br><span class="line">​      <span class="comment"># 返回Proxy对象列表</span></span><br><span class="line"></span><br><span class="line">​      <span class="keyword">yield</span> <span class="keyword">from</span> proxies</span><br></pre></td></tr></table></figure>





<h4 id="实现四个具体爬虫爬虫"><a href="#实现四个具体爬虫爬虫" class="headerlink" title="实现四个具体爬虫爬虫:"></a>实现四个具体爬虫爬虫:</h4><h5 id="目标∶通过继承通用爬虫-实现多个具体爬虫-分别从各个免费代理IP网站上抓取代理IP"><a href="#目标∶通过继承通用爬虫-实现多个具体爬虫-分别从各个免费代理IP网站上抓取代理IP" class="headerlink" title="目标∶通过继承通用爬虫,实现多个具体爬虫,分别从各个免费代理IP网站上抓取代理IP"></a>目标∶通过继承通用爬虫,实现多个具体爬虫,分别从各个免费代理IP网站上抓取代理IP</h5><h5 id="步骤-5"><a href="#步骤-5" class="headerlink" title="步骤"></a>步骤</h5><p>​        1.实现西刺代理爬虫: <a target="_blank" rel="noopener" href="http://www.xicidaili.com/nn/1">http://www.xicidaili.com/nn/1</a><br>​            定义一个类,继承通用爬虫类(BasicSpider)<br>​            提供urls, group_xpath 和detail_xpath</p>
<p>​    2.实现 ip3366代理爬虫: <a target="_blank" rel="noopener" href="http://www.ip3366.net/free/?stype=1&amp;page=1">http://www.ip3366.net/free/?stype=1&amp;page=1</a><br>​            定义一个类,继承通用爬虫类(BasicSpider)<br>​            提供urls, group_xpath和detail_xpath</p>
<p>​    3.实现快代理爬虫: https: //www. kuaidaili.com/free/inha/1/<br>​            定义一个类,继承通用爬虫类(BasicSpider)<br>​            提供urls, group_xpath和detail_xpath</p>
<p>​    4.实现 proxylistplus代理爬虫: <a target="_blank" rel="noopener" href="https://list.proxylistplus.com/Fresh-HTTP-Proxy-List-1">https://list.proxylistplus.com/Fresh-HTTP-Proxy-List-1</a><br>​        定义一个类,继承通用爬虫类(BasicSpider)<br>​        提供urls, group_xpath和detail_xpath</p>
<p>​    5.实现66ip 爬虫: <a target="_blank" rel="noopener" href="http://www.66ip.cn/1.html">http://www.66ip.cn/1.html</a><br>​        定义一个类,继承通用爬虫类(BasicSpider)提供urls, group_xpath和detail_xpath<br>​        ·由于66ip网页进行js + cookie反爬,需要重写父类的get_page_from_url方法</p>
<h4 id="代码-6"><a href="#代码-6" class="headerlink" title="代码"></a>代码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> timeimport randomimport js2pyimport requestsimport re</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> core.proxy_spider.base_spider <span class="keyword">import</span> *<span class="keyword">from</span> utils.http <span class="keyword">import</span> get_request_headers<span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">1.实现西刺代理爬虫: http://www.xicidaili.com/nn/1</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> 定义一个类,继承通用爬虫类(BasicSpider)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> 提供urls, group_xpath 和detail_xpath</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span><span class="comment"># 目前测试用不到</span></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="comment"># url 列表</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">XiChiSpiers</span> (<span class="params">base_spider</span>):</span></span><br><span class="line">  urls = [<span class="string">&#x27;http://www.xicidaili.com/nn/&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line"></span><br><span class="line">  <span class="comment">#分组的xpath 用于获取代理ip信息的标签列表</span></span><br><span class="line"></span><br><span class="line">  group_xpath = <span class="string">&#x27;//*[@id=&quot;ip_list&quot;]/tr[position()&gt;1]&#x27;</span> <span class="comment"># position()&gt;1 去掉不需要的头</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">#组内 xpath 用于提取 ip port area</span></span><br><span class="line"></span><br><span class="line">  detail_xpath = &#123;</span><br><span class="line"></span><br><span class="line">​    <span class="string">&#x27;ip&#x27;</span>: <span class="string">&#x27;./td[2]/text()&#x27;</span>,</span><br><span class="line"></span><br><span class="line">​    <span class="string">&#x27;port&#x27;</span>: <span class="string">&#x27;./td[3]/text()&#x27;</span>,</span><br><span class="line"></span><br><span class="line">​    <span class="string">&#x27;area&#x27;</span>: <span class="string">&#x27;./td[4]/a/text()&#x27;</span></span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">2.实现 ip3366代理爬虫: http://www.ip3366.net/free/?stype=1&amp;page=1</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">·定义一个类,继承通用爬虫类(BasicSpider)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">提供urls, group_xpath和detail_xpath</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ip3366_Spiers</span>(<span class="params">base_spider</span>):</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># url 列表</span></span><br><span class="line"></span><br><span class="line">  urls = [<span class="string">&#x27;http://www.ip3366.net/free/?stype=&#123;&#125;&amp;page=1&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(i,j) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">3</span>) <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line"></span><br><span class="line">  <span class="comment">#分组的xpath 用于获取代理ip信息的标签列表</span></span><br><span class="line"></span><br><span class="line">  group_xpath = <span class="string">&#x27;//*[@id=&quot;list&quot;]/table/tbody/tr&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">#组内 xpath 用于提取 ip port area</span></span><br><span class="line"></span><br><span class="line">  detail_xpath = &#123;</span><br><span class="line"></span><br><span class="line">​    <span class="string">&#x27;ip&#x27;</span>: <span class="string">&#x27;./td[1]/text()&#x27;</span>,</span><br><span class="line"></span><br><span class="line">​    <span class="string">&#x27;port&#x27;</span>: <span class="string">&#x27;./td[2]/text()&#x27;</span>,</span><br><span class="line"></span><br><span class="line">​    <span class="string">&#x27;area&#x27;</span>: <span class="string">&#x27;./td[5]/text()&#x27;</span>,</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">3.实现快代理爬虫: https://www.kuaidaili.com/free/inha/1/</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">·定义一个类,继承通用爬虫类(BasicSpider)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">·提供urls, group_xpath和detail_xpath</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KuaiDaili_Spiers</span>(<span class="params">base_spider</span>):</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># url 列表</span></span><br><span class="line"></span><br><span class="line">  urls = [<span class="string">&#x27;https://www.kuaidaili.com/free/inha/&#123;&#125;/&#x27;</span>.<span class="built_in">format</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line"></span><br><span class="line">  <span class="comment">#分组的xpath 用于获取代理ip信息的标签列表</span></span><br><span class="line"></span><br><span class="line">  group_xpath = <span class="string">&#x27;//*[@id=&quot;list&quot;]/table/tbody/tr&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">#组内 xpath 用于提取 ip port area</span></span><br><span class="line"></span><br><span class="line">  detail_xpath = &#123;</span><br><span class="line"></span><br><span class="line">​    <span class="string">&#x27;ip&#x27;</span>: <span class="string">&#x27;./td[1]/text()&#x27;</span>,</span><br><span class="line"></span><br><span class="line">​    <span class="string">&#x27;port&#x27;</span>: <span class="string">&#x27;./td[2]/text()&#x27;</span>,</span><br><span class="line"></span><br><span class="line">​    <span class="string">&#x27;area&#x27;</span>: <span class="string">&#x27;./td[5]/text()&#x27;</span>,</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">get_page_from_url</span>(<span class="params">self,url</span>):</span></span><br><span class="line"></span><br><span class="line">​    <span class="comment"># 随机等待1 - 3 s 防止反爬</span></span><br><span class="line"></span><br><span class="line">​    time.sleep(random.uniform(<span class="number">1</span>,<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">​    <span class="keyword">return</span> <span class="built_in">super</span>().get_page_from_url(url)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">4.实现 proxylistplus代理爬虫: https://list.proxylistplus.com/Fresh-HTTP-Proxy-List-1</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">定义一个类,继承通用爬虫类(BasicSpider)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">·提供urls, group_xpath和detail_xpath</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Proxylistplus_Spiers</span>(<span class="params">base_spider</span>):</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># url 列表</span></span><br><span class="line"></span><br><span class="line">  urls = [<span class="string">&#x27;https://list.proxylistplus.com/Fresh-HTTP-Proxy-List-&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line"></span><br><span class="line">  <span class="comment">#分组的xpath 用于获取代理ip信息的标签列表</span></span><br><span class="line"></span><br><span class="line">  group_xpath = <span class="string">&#x27;//*[@id=&quot;page&quot;]/table[2]/tr[position()&gt;2]&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">#组内 xpath 用于提取 ip port area</span></span><br><span class="line"></span><br><span class="line">  detail_xpath = &#123;</span><br><span class="line"></span><br><span class="line">​    <span class="string">&#x27;ip&#x27;</span>: <span class="string">&#x27;./td[2]/text()&#x27;</span>,</span><br><span class="line"></span><br><span class="line">​    <span class="string">&#x27;port&#x27;</span>: <span class="string">&#x27;./td[3]/text()&#x27;</span>,</span><br><span class="line"></span><br><span class="line">​    <span class="string">&#x27;area&#x27;</span>: <span class="string">&#x27;./td[5]/text()&#x27;</span>,</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">get_page_from_url</span>(<span class="params">self,url</span>):</span></span><br><span class="line"></span><br><span class="line">​    <span class="comment"># 随机等待1 - 3 s 防止反爬</span></span><br><span class="line"></span><br><span class="line">​    time.sleep(random.uniform(<span class="number">1</span>,<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">​    <span class="keyword">return</span> <span class="built_in">super</span>().get_page_from_url(url)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">5.实现66ip 爬虫: http://www.66ip.cn/1.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">定义一个类,继承通用爬虫类(BasicSpider)提供urls, group_xpath和detail_xpath</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">·由于66ip网页进行js + cookie反爬,需要重写父类的get_page_from_url方法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Ip66_spider</span>(<span class="params">base_spider</span>):</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># url 列表</span></span><br><span class="line"></span><br><span class="line">  urls = [<span class="string">&#x27;http://www.66ip.cn/&#123;&#125;.html&#x27;</span>.<span class="built_in">format</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">11</span>)]</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 分组的xpath 用于获取代理ip信息的标签列表</span></span><br><span class="line"></span><br><span class="line">  group_xpath = <span class="string">&#x27;//*[@id=&quot;main&quot;]/div[1]/div[2]/div[1]/table/tr[position()&gt;1]&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 组内 xpath 用于提取 ip port area</span></span><br><span class="line"></span><br><span class="line">  detail_xpath = &#123;</span><br><span class="line"></span><br><span class="line">​    <span class="string">&#x27;ip&#x27;</span>: <span class="string">&#x27;./td[1]/text()&#x27;</span>,</span><br><span class="line"></span><br><span class="line">​    <span class="string">&#x27;port&#x27;</span>: <span class="string">&#x27;./td[2]/text()&#x27;</span>,</span><br><span class="line"></span><br><span class="line">​    <span class="string">&#x27;area&#x27;</span>: <span class="string">&#x27;./td[3]/text()&#x27;</span>,</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 由于66ip网页进行js + cookie反爬,需要重写父类的get_page_from_url方法</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">get_page_from_url</span>(<span class="params">self,url</span>):</span></span><br><span class="line"></span><br><span class="line">​    header = get_request_headers()</span><br><span class="line"></span><br><span class="line">​    response = requests.get(url,headers=header)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​    <span class="keyword">if</span> response.status_code == <span class="number">521</span>:</span><br><span class="line"></span><br><span class="line">​      <span class="comment"># 生成cookie信息 ,再携带 cookie 信息发送请求</span></span><br><span class="line"></span><br><span class="line">​      <span class="comment"># 生成“ ydclearance ” cookie信息</span></span><br><span class="line"></span><br><span class="line">​      <span class="comment"># 1 确定_ydclearance是从哪里来的;</span></span><br><span class="line"></span><br><span class="line">​      <span class="comment">#  观察发现:这个cookie信息不使用通过服务器响应设置过来的;那么他就是通过js生成。</span></span><br><span class="line"></span><br><span class="line">​      <span class="comment"># 2 第一次发送请求的页面中,有一个生成这个cookie的js;执行这段js,</span></span><br><span class="line"></span><br><span class="line">​      <span class="comment">#  生成我们需要的cooki#这段js是经过加密处理后的js,真正js在&quot;po”中.</span></span><br><span class="line"></span><br><span class="line">​      <span class="comment"># 提取“jp ( 107)”调用函数的方法,以及函数</span></span><br><span class="line"></span><br><span class="line">​      result = re.findall(<span class="string">&#x27;window.onload=setTimeout\(&quot;(.+?)&quot;,200\);\s*(.+?)\s*&lt;/scipt&gt;&#x27;</span>,response.content.decode(<span class="string">&#x27;GBK&#x27;</span>))</span><br><span class="line"></span><br><span class="line">​      <span class="comment">#执行提取出来的js函数</span></span><br><span class="line"></span><br><span class="line">​      func_str = result[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">​      func_str = func_str.replace(<span class="string">&#x27;eval(&quot;qo=eval;qo(po);&quot;)&#x27;</span>,<span class="string">&#x27;return po&#x27;</span>)</span><br><span class="line"></span><br><span class="line">​      <span class="comment"># 获取js的环境</span></span><br><span class="line"></span><br><span class="line">​      context = js2py.EvalJs()</span><br><span class="line"></span><br><span class="line">​      <span class="comment"># 执行func_str</span></span><br><span class="line"></span><br><span class="line">​      context.execute(func_str)</span><br><span class="line"></span><br><span class="line">​      context.execute(<span class="string">&#x27;code = &#123;&#125;;&#x27;</span>.<span class="built_in">format</span>(result[<span class="number">0</span>][<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line">​      <span class="comment"># 获取cookie</span></span><br><span class="line"></span><br><span class="line">​      cookie_str = re.findall(<span class="string">&quot;document.cookie=&#x27;(.+?);&quot;</span>,context.code)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">​      header[<span class="string">&#x27;Cookie&#x27;</span>] = cookie_str</span><br><span class="line"></span><br><span class="line">​      response = requests.get(url,headers=header)</span><br><span class="line"></span><br><span class="line">​      <span class="keyword">return</span> response.content.decode(<span class="string">&#x27;GBK&#x27;</span>)</span><br><span class="line"></span><br><span class="line">​    <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">​      <span class="keyword">return</span> response.content.decode(<span class="string">&#x27;GBK&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">if __name__ == &#x27;__main__&#x27;:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  xc =Ip66_spider()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  for proxy in xc.get_proxies():</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​    print(proxy)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="实现运行爬虫模块"><a href="#实现运行爬虫模块" class="headerlink" title="实现运行爬虫模块"></a>实现运行爬虫模块</h3><h5 id="目标∶根据配置文件信息-加载爬虫-抓取代理IP-进行校验-如果可用-写入到数据库中"><a href="#目标∶根据配置文件信息-加载爬虫-抓取代理IP-进行校验-如果可用-写入到数据库中" class="headerlink" title="目标∶根据配置文件信息,加载爬虫,抓取代理IP,进行校验,如果可用,写入到数据库中"></a>目标∶根据配置文件信息,加载爬虫,抓取代理IP,进行校验,如果可用,写入到数据库中</h5><h5 id="代码-7"><a href="#代码-7" class="headerlink" title="代码"></a>代码</h5> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> gevent.monkey</span><br><span class="line">gevent.monkey.patch_all()</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    打猴子补丁：</span></span><br><span class="line"><span class="string">        即在运行时对方法 / 类 / 属性 / 功能进行修改，把新的代码作为解决方案代替原有的程序，</span></span><br><span class="line"><span class="string">        也就是为其打上补丁。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 导入协程池</span></span><br><span class="line"><span class="keyword">from</span> gevent.pool <span class="keyword">import</span> Pool</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用schedule模块,实现每隔一定的时间,执行一次爬取任务</span></span><br><span class="line"><span class="keyword">import</span> schedule</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> importlib</span><br><span class="line"><span class="keyword">import</span> core.proxy_spider.proxy_spiers</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> settings <span class="keyword">import</span> PROXIES_SPIDER</span><br><span class="line"><span class="keyword">from</span> core.proxy_validate.httpbin_validator <span class="keyword">import</span> check_proxy</span><br><span class="line"><span class="keyword">from</span> core.db.mongo_pool <span class="keyword">import</span> MongoPool</span><br><span class="line"><span class="keyword">from</span> utils.log <span class="keyword">import</span> logger</span><br><span class="line"><span class="keyword">from</span> settings <span class="keyword">import</span> RUN_SPIDER_INTERVAL</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">### 实现运行爬虫模块</span></span><br><span class="line"><span class="string">目标∶根据配置文件信息,加载爬虫,抓取代理IP,进行校验,如果可用,写入到数据库中</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">1. 在run_spider.py中，创建RunSpider类</span></span><br><span class="line"><span class="string">2. 提供一个运行爬虫的run方法,作为运行爬虫的入口,实现核心的处理逻辑</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      根据配置文件信息,获取爬虫对象列表.</span></span><br><span class="line"><span class="string">      遍历爬虫对象列表,获取爬虫对象,遍历爬虫对象的get_proxies方法,获取代理IP</span></span><br><span class="line"><span class="string">      检测代理IP(代理IP检测模块)</span></span><br><span class="line"><span class="string">      如果可用,写入数据库(数据库模块)</span></span><br><span class="line"><span class="string">      处理异常,防止一个爬虫内部出错了,影响其他的爬虫.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">3. 使用异步来执行每一个爬虫任务,以提高抓取代理IP效率</span></span><br><span class="line"><span class="string">	在init方法中创建协程池对象</span></span><br><span class="line"><span class="string">	把处理一个代理爬虫的代码抽到一个方法使用异步执行这个方法</span></span><br><span class="line"><span class="string">	调用协程的join方法,让当前线程等待队列任务的完成.</span></span><br><span class="line"><span class="string">	</span></span><br><span class="line"><span class="string">4. 使用schedule模块,实现每隔一定的时间,执行一次爬取任务</span></span><br><span class="line"><span class="string">      定义一个start的类方法</span></span><br><span class="line"><span class="string">      创建当前类的对象,调用run方法</span></span><br><span class="line"><span class="string">      使用schedule模块,每隔一定的时间,执行当前对象的run方法     </span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RunSpider</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 创建数据库对象</span></span><br><span class="line">        self.mongo_pool = MongoPool()</span><br><span class="line">        <span class="comment"># 创建协程池对象</span></span><br><span class="line">        self.coroutime_pool = Pool()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_spider_from_settings</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 遍历爬虫列表，获取每个爬虫的全类名</span></span><br><span class="line">        <span class="keyword">for</span> full_class_name <span class="keyword">in</span> PROXIES_SPIDER:</span><br><span class="line">            <span class="comment"># full_class_name -- core/proxy_spider/proxy_spiers.Ip66_spider</span></span><br><span class="line">            model_name , class_name = full_class_name.rsplit(<span class="string">&#x27;.&#x27;</span>,maxsplit=<span class="number">1</span>)</span><br><span class="line">            <span class="comment"># 动态导入 根据模块名导入模块</span></span><br><span class="line">            model = importlib.import_module(model_name)</span><br><span class="line">            <span class="comment"># 根据类名 获取类</span></span><br><span class="line">            cls = <span class="built_in">getattr</span>(model,class_name)</span><br><span class="line">            <span class="comment"># 创建爬虫对象</span></span><br><span class="line">            spier = cls()</span><br><span class="line">            <span class="keyword">yield</span> spier</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 获取爬虫对象列表</span></span><br><span class="line">        spiders =self.get_spider_from_settings()</span><br><span class="line">        <span class="comment"># 遍历爬虫对象列表, 获取爬虫对象</span></span><br><span class="line">        <span class="keyword">for</span> spider <span class="keyword">in</span> spiders:</span><br><span class="line">            <span class="comment"># 遍历爬虫对象的get_proxies方法,获取代理IP</span></span><br><span class="line">            <span class="comment"># 处理异常,防止一个爬虫内部出错了,影响其他的爬虫.</span></span><br><span class="line">            <span class="comment"># 使用异步执行这个方法</span></span><br><span class="line">            <span class="comment"># self.__execute_one_spider_task(spider)</span></span><br><span class="line">            self.coroutime_pool.apply_async(self.__execute_one_spider_task,args=(spider,))</span><br><span class="line">        <span class="comment"># 	调用协程的join方法,让当前线程等待队列任务的完成.</span></span><br><span class="line">        self.coroutime_pool.join()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__execute_one_spider_task</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        <span class="comment"># 把处理一个代理爬虫的代码抽到一个方法使用异步执行这个方法</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">for</span> proxy <span class="keyword">in</span> spider.get_proxies():</span><br><span class="line">                <span class="comment"># print(proxy)</span></span><br><span class="line">                <span class="comment"># 检测代理IP(代理IP检测模块)</span></span><br><span class="line">                proxy = check_proxy(proxy)</span><br><span class="line">                <span class="keyword">if</span> proxy.speed != -<span class="number">1</span>:</span><br><span class="line">                    self.mongo_pool.insert_one(proxy)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> ex:</span><br><span class="line">            logger.exception(ex)</span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start</span>(<span class="params">cls</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">            定义一个start的类方法</span></span><br><span class="line"><span class="string">            创建当前类的对象,调用run方法</span></span><br><span class="line"><span class="string">            使用schedule模块,每隔一定的时间,执行当前对象的run方法</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        rs = RunSpider()</span><br><span class="line">        rs.run()</span><br><span class="line">        <span class="comment"># 每隔一定的时间写入配置文件</span></span><br><span class="line">        schedule.every(RUN_SPIDER_INTERVAL).hour.do(rs.run())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 检测是否到时间了</span></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            schedule.run_pending()</span><br><span class="line">            <span class="comment"># 每隔一分钟检测一次</span></span><br><span class="line">            time.sleep(<span class="number">60</span>)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># rs = RunSpider()</span></span><br><span class="line">    <span class="comment"># rs.run()</span></span><br><span class="line">    RunSpider.start()</span><br></pre></td></tr></table></figure>


<h3 id="实现代理ip检测模块"><a href="#实现代理ip检测模块" class="headerlink" title="实现代理ip检测模块"></a>实现代理ip检测模块</h3><h5 id="目的-检查代理IP可用性-保证代理池中代理IP基本可用思路"><a href="#目的-检查代理IP可用性-保证代理池中代理IP基本可用思路" class="headerlink" title="目的:检查代理IP可用性,保证代理池中代理IP基本可用思路"></a>目的:检查代理IP可用性,保证代理池中代理IP基本可用思路</h5><h5 id="代码-8"><a href="#代码-8" class="headerlink" title="代码"></a>代码</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span>  queue <span class="keyword">import</span> Queue</span><br><span class="line"><span class="keyword">import</span> schedule</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27; 猴子补丁&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">import</span> gevent.monkey</span><br><span class="line">gevent.monkey.patch_all()</span><br><span class="line"><span class="keyword">from</span> settings <span class="keyword">import</span> MAX_SCORE,TEST_TIMEOUT,TEST_SPIDER_INTERVAL</span><br><span class="line"><span class="keyword">from</span> gevent.pool <span class="keyword">import</span> Pool</span><br><span class="line"><span class="keyword">from</span> core.db.mongo_pool <span class="keyword">import</span> MongoPool</span><br><span class="line"><span class="keyword">from</span> core.proxy_validate.httpbin_validator <span class="keyword">import</span> check_proxy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">## 实现代理ip检测模块</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">##### 1.   在proxy_test.py中,创建ProxyTester类</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">##### 2.提供一个 run方法,用于处理检测代理IP核心逻辑</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">		i.从数据库中获取所有代理IP</span></span><br><span class="line"><span class="string">		</span></span><br><span class="line"><span class="string">		ii.遍历代理IP列表</span></span><br><span class="line"><span class="string">		</span></span><br><span class="line"><span class="string">		iii.检查代理可用性		</span></span><br><span class="line"><span class="string">			如果代理不可用,让代理分数-1,如果代理分数等于0就从数据库中删除该代理代理IP</span></span><br><span class="line"><span class="string">			如果代理可用，就恢复该代理的分数,更新到数据库中</span></span><br><span class="line"><span class="string">			</span></span><br><span class="line"><span class="string">3.为了提高检查的速度,使用异步来执行检测任务</span></span><br><span class="line"><span class="string">		i.把要检测的代理IP,放到队列中</span></span><br><span class="line"><span class="string">		ii.把检查一个代理可用性的代码,抽取到一个方法中;从队列中获取代理IP,进行检查调度队列的task_done方法</span></span><br><span class="line"><span class="string">		ii.通过异步回调,使用死循环不断执行这个方法，</span></span><br><span class="line"><span class="string">		iv.开启多个异步任务,来处理代理IP的检测;可以通过配置文件指定异步数量</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">##### 4.使用schedule模块,每隔一定的时间,执行一次检测任务</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​	    i.定义类方法start ,用于启动检测模块**</span></span><br><span class="line"><span class="string">​	    ii.在 start方法中**</span></span><br><span class="line"><span class="string">    ​	    i.创建本类对象**</span></span><br><span class="line"><span class="string">    ​ 	  ii．调用run方法**</span></span><br><span class="line"><span class="string">    ​	    iii.每间隔一定时间,执行一下, run方法**</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ProxyTester</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 创建数据库对象</span></span><br><span class="line">        self.mongo_pool = MongoPool()</span><br><span class="line">        <span class="comment"># 创建协程池</span></span><br><span class="line">        self.coroutime_pool = Pool()</span><br><span class="line">        <span class="comment"># 创建队列</span></span><br><span class="line">        self.queue = Queue()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__check_callback</span>(<span class="params">self,temp</span>):</span></span><br><span class="line">        self.coroutime_pool.apply_async(self.__check_one_proxy,callback=self.__check_one_proxy)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 从数据库中获取所有代理IP</span></span><br><span class="line">        proxies = self.mongo_pool.find_all()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> proxy <span class="keyword">in</span> proxies:</span><br><span class="line">            <span class="comment"># 遍历代理IP列表</span></span><br><span class="line">            <span class="comment"># self.__check_one_proxy(proxy)</span></span><br><span class="line">            <span class="comment"># 把代理ip添加到队列</span></span><br><span class="line">            self.queue.put(proxy)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(TEST_TIMEOUT):</span><br><span class="line">                <span class="comment"># 开启多个一个异步任务, 来处理代理IP的检测;</span></span><br><span class="line">                <span class="comment"># 通过异步回调,使用死循环不断执行这个方法</span></span><br><span class="line">                self.coroutime_pool.apply_async(self.__check_one_proxy, callback=self.__check_callback)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 让当前线程等待队列任务的完成</span></span><br><span class="line">        self.queue.join()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__check_one_proxy</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 重队列中取出代理ip</span></span><br><span class="line">        proxy = self.queue.get()</span><br><span class="line">        <span class="comment"># 检查代理可用性</span></span><br><span class="line">        proxy = check_proxy(proxy)</span><br><span class="line">        <span class="comment"># 如果代理不可用,让代理分数-1,如果代理分数等于0就从数据库中删除该代理代理IP</span></span><br><span class="line">        <span class="keyword">if</span> proxy.speed == -<span class="number">1</span>:</span><br><span class="line">            proxy.score -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> proxy.score == <span class="number">0</span>:</span><br><span class="line">                self.mongo_pool.delect_one(proxy)</span><br><span class="line">        <span class="comment"># 如果代理可用，就恢复该代理的分数,更新到数据库中</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            proxy.score = MAX_SCORE</span><br><span class="line">            self.mongo_pool.update_one(proxy)</span><br><span class="line">        <span class="comment"># 进行检查调度队列的task_done方法 ， 表示这个代理ip检测完了</span></span><br><span class="line">        self.queue.task_done()</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start</span>(<span class="params">cls</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        	i.创建本类对象</span></span><br><span class="line"><span class="string">    ​	   ii．调用run方法</span></span><br><span class="line"><span class="string">    ​	  iii.每间隔一定时间,执行一下, run方法</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        pt = cls()</span><br><span class="line">        pt.run()</span><br><span class="line">        schedule.every(TEST_SPIDER_INTERVAL).hour.do(pt.run())</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            schedule.run_pending()</span><br><span class="line">            <span class="comment"># 每隔一分钟检测一下</span></span><br><span class="line">            time.sleep(<span class="number">60</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    ProxyTester.start()</span><br><span class="line">    </span><br></pre></td></tr></table></figure>





<h3 id="实现代理ip池的api模块"><a href="#实现代理ip池的api模块" class="headerlink" title="实现代理ip池的api模块"></a>实现代理ip池的api模块</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">目标:</span><br><span class="line">    为爬虫提供高可用代理IP的服务接口</span><br><span class="line">步骤︰</span><br><span class="line">    实现根据协议类型和域名,提供随机的获取高可用代理lP的服务。</span><br><span class="line">    实现根据协议类型和域名,提供获取多个高可用代理IP的服务。</span><br><span class="line">    实现给指定的IP上追加不可用域名的服务</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="代码-9"><a href="#代码-9" class="headerlink" title="代码"></a>代码</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">from</span> core.db.mongo_pool <span class="keyword">import</span> MongoPool</span><br><span class="line"><span class="keyword">from</span> settings <span class="keyword">import</span> PROXIES_MAX_COUNT</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">目标:</span></span><br><span class="line"><span class="string">    为爬虫提供高可用代理IP的服务接口</span></span><br><span class="line"><span class="string">步骤︰</span></span><br><span class="line"><span class="string">    实现根据协议类型和域名,提供随机的获取高可用代理lP的服务。</span></span><br><span class="line"><span class="string">    实现根据协议类型和域名,提供获取多个高可用代理IP的服务。</span></span><br><span class="line"><span class="string">    实现给指定的IP上追加不可用域名的服务</span></span><br><span class="line"><span class="string">实现:</span></span><br><span class="line"><span class="string">    在proxy_api.py中,创建ProxyApi类。</span></span><br><span class="line"><span class="string">    实现初始方法</span></span><br><span class="line"><span class="string">    初始一个Flask的Web服务</span></span><br><span class="line"><span class="string">    实现根据协议类型和域名,提供随机的获取高可用代理IP的服务</span></span><br><span class="line"><span class="string">        可用通过protocol和domain参数对lIP进行过滤</span></span><br><span class="line"><span class="string">        protocol :当前请求的协议类型</span></span><br><span class="line"><span class="string">        domain :当前请求域名</span></span><br><span class="line"><span class="string">    实现根据协议类型和域名,提供获取多个高可用代理IP的服务</span></span><br><span class="line"><span class="string">        可用通过protocol和domain参数对IP进行过滤实现给指定的IP上追加不可用域名的服务</span></span><br><span class="line"><span class="string">        如果在获取IP的时候,有指定域名参数,将不在获取该IP,从而进一步提高代理IP的可用性.</span></span><br><span class="line"><span class="string">    实现run方法,用于启动Flask的WEB服务</span></span><br><span class="line"><span class="string">    实现start的类方法,用于通过类名,启动服务</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ProxyApi</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        实现初始方法</span></span><br><span class="line"><span class="string">        初始一个Flask的Web服务</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.app = Flask(__name__)</span><br><span class="line">        self.mongo_pool = MongoPool()</span><br><span class="line"><span class="meta">        @self.app.route(<span class="params"><span class="string">&#x27;/random&#x27;</span></span>)</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">random</span>():</span></span><br><span class="line">            <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">                实现根据协议类型和域名,提供随机的获取高可用代理IP的服务</span></span><br><span class="line"><span class="string">                    可用通过protocol和domain参数对lIP进行过滤</span></span><br><span class="line"><span class="string">                    protocol :当前请求的协议类型</span></span><br><span class="line"><span class="string">                    domain :当前请求域名</span></span><br><span class="line"><span class="string">            &#x27;&#x27;&#x27;</span></span><br><span class="line">            protocol = request.args.get(<span class="string">&#x27;protocol&#x27;</span>)</span><br><span class="line">            domain  =  request.args.get(<span class="string">&#x27;domain&#x27;</span>)</span><br><span class="line">            proxy = self.mongo_pool.random_proxy(protocol=protocol,domain =domain,count=PROXIES_MAX_COUNT)</span><br><span class="line">            <span class="keyword">if</span> protocol:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">&#x27;&#123;&#125;://&#123;&#125;:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(protocol,proxy.ip,proxy.port)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">&#x27;&#123;&#125;:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(proxy.ip,proxy.port)</span><br><span class="line"></span><br><span class="line"><span class="meta">        @self.app.route(<span class="params"><span class="string">&#x27;/proxies&#x27;</span></span>)</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">proxies</span>():</span></span><br><span class="line">            <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">                实现根据协议类型和域名,提供获取多个高可用代理IP的服务</span></span><br><span class="line"><span class="string">                    可用通过protocol和domain参数对IP进行过滤实现给指定的IP上追加不可用域名的服务</span></span><br><span class="line"><span class="string">                    如果在获取IP的时候,有指定域名参数,将不在获取该IP,从而进一步提高代理IP的可用性.</span></span><br><span class="line"><span class="string">            &#x27;&#x27;&#x27;</span></span><br><span class="line">            protocol = request.args.get(<span class="string">&#x27;protocol&#x27;</span>)</span><br><span class="line">            domain = request.args.get(<span class="string">&#x27;domain&#x27;</span>)</span><br><span class="line">            <span class="comment"># 获取代理对象的列表</span></span><br><span class="line">            proxies = self.mongo_pool.get_proxies(protocol,domain,PROXIES_MAX_COUNT)</span><br><span class="line">            <span class="comment"># 将对象列表转换为字典 进而进行 json 序列化</span></span><br><span class="line">            proxies = [proxy.__dict__ <span class="keyword">for</span> proxy <span class="keyword">in</span> proxies]</span><br><span class="line">            <span class="comment"># 解释失败</span></span><br><span class="line">            <span class="keyword">return</span> json.dumps(proxies, sort_keys=<span class="literal">True</span>, indent=<span class="number">4</span>, separators=(<span class="string">&#x27;,&#x27;</span>, <span class="string">&#x27;:&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="meta">        @self.app.route(<span class="params"><span class="string">&#x27;/disable_domain&#x27;</span></span>)</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">disable_domain</span>():</span></span><br><span class="line">            <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">                在获取ip的时候如果有指定的域名参数</span></span><br><span class="line"><span class="string">                将不获取此ip</span></span><br><span class="line"><span class="string">            &#x27;&#x27;&#x27;</span></span><br><span class="line">            ip = request.args.get(<span class="string">&#x27;ip&#x27;</span>)</span><br><span class="line">            domain = request.args.get(<span class="string">&#x27;domain&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> ip == <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">&#x27;请输入ip参数&#x27;</span></span><br><span class="line">            <span class="keyword">if</span> domain ==<span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">&#x27;请输入域名domain参数&#x27;</span></span><br><span class="line">            self.mongo_pool.disable_domain(ip,domain)</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&#x27;&#123;&#125; 禁用域名 &#123;&#125; 成功&#x27;</span>.<span class="built_in">format</span>(ip,domain)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span> (<span class="params">self</span>):</span></span><br><span class="line">        self.app.run(<span class="string">&#x27;0.0.0.0&#x27;</span>,port=<span class="number">18888</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start</span>(<span class="params">cls</span>):</span></span><br><span class="line">        pa = cls()</span><br><span class="line">        pa.run()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">     ProxyApi.start()</span><br><span class="line">    </span><br></pre></td></tr></table></figure>


<h3 id="实现代理ip池启动入口"><a href="#实现代理ip池启动入口" class="headerlink" title="实现代理ip池启动入口"></a>实现代理ip池启动入口</h3><h5 id="目标-把启动爬虫，启动检测代理IP，启动WEB服务统一到一起"><a href="#目标-把启动爬虫，启动检测代理IP，启动WEB服务统一到一起" class="headerlink" title="目标:把启动爬虫，启动检测代理IP，启动WEB服务统一到一起"></a>目标:把启动爬虫，启动检测代理IP，启动WEB服务统一到一起</h5><h5 id="代码-10"><a href="#代码-10" class="headerlink" title="代码"></a>代码</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">main.py</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">目标:</span></span><br><span class="line"><span class="string">    把启动爬虫，启动检测代理IP，启动WEB服务统一到一起</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">思路∶</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​	开启三个进程,分别用于启动爬虫，检测代理IP,WEB服务</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">步骤:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​	定义一个run方法用于启动动代理池</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​	定义一个列表,用于存储要启动的进程</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​	创建启动爬虫的进程,添加到列表中-</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​	创建启动检测的进程,添加到列表中</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​	创建启动提供API服务的进程,添加到列表中</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​	遍历进程列表,启动所有进程</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">​	遍历进程列表,让主进程等待子进程的完成。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> 在 if _name_ == &#x27; __main__&#x27;:中调用run方法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process</span><br><span class="line"><span class="keyword">from</span> core.proxy_spider.run_spider <span class="keyword">import</span> RunSpider</span><br><span class="line"><span class="keyword">from</span> core.proxy_test <span class="keyword">import</span> ProxyTester</span><br><span class="line"><span class="keyword">from</span> core.proxy_api <span class="keyword">import</span> ProxyApi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span>():</span></span><br><span class="line">    <span class="comment"># 定义一个列表 存储启动进程</span></span><br><span class="line">    process_list = []</span><br><span class="line">    <span class="comment"># 启动爬虫的进程</span></span><br><span class="line">    process_list.append(Process(target=RunSpider.start))</span><br><span class="line">    <span class="comment"># 启动检测的进程</span></span><br><span class="line">    process_list.append(Process(target=ProxyTester.start))</span><br><span class="line">    <span class="comment"># 启动爬虫API</span></span><br><span class="line">    process_list.append(Process(target=ProxyApi.start))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> process <span class="keyword">in</span> process_list:</span><br><span class="line">        <span class="comment"># 遍历进程列表,启动所有进程</span></span><br><span class="line">        <span class="comment"># 设置守护进程</span></span><br><span class="line">        process.daemon = <span class="literal">True</span></span><br><span class="line">        process.start()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> process <span class="keyword">in</span> process_list:</span><br><span class="line">        <span class="comment"># 遍历进程列表,让主进程等待子进程的完成。</span></span><br><span class="line">        process.join()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    run()</span><br></pre></td></tr></table></figure>



      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://maolululu.github.io/maolu.github.io/2021/04/24/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/maolu.github.io/images/toux.gif">
      <meta itemprop="name" content="maolu">
      <meta itemprop="description" content="Happy Coding">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="maolu">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/maolu.github.io/2021/04/24/hello-world/" class="post-title-link" itemprop="url">Hello World</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-04-24 13:29:11" itemprop="dateCreated datePublished" datetime="2021-04-24T13:29:11+08:00">2021-04-24</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="maolu"
      src="/maolu.github.io/images/toux.gif">
  <p class="site-author-name" itemprop="name">maolu</p>
  <div class="site-description" itemprop="description">Happy Coding</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/maolu.github.io/archives/">
        
          <span class="site-state-item-count">3</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">maolu</span>
</div>

<!--
  <div class="code-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>
-->

        








      </div>
    </footer>
  </div>

  
  <script src="/maolu.github.io/lib/anime.min.js"></script>
  <script src="/maolu.github.io/lib/velocity/velocity.min.js"></script>
  <script src="/maolu.github.io/lib/velocity/velocity.ui.min.js"></script>

<script src="/maolu.github.io/js/utils.js"></script>

<script src="/maolu.github.io/js/motion.js"></script>


<script src="/maolu.github.io/js/schemes/pisces.js"></script>


<script src="/maolu.github.io/js/next-boot.js"></script>




  















  

  

<script src="/maolu.github.io/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/maolu.github.io/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true}});</script></body>
</html>
